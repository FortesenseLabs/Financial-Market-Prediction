{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from azureml.core.model import Model\n",
    "import numpy as np    # we're going to use numpy to process input and output data\n",
    "#import onnxruntime    # to inference ONNX models, we use the ONNX Runtime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import requests\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "\n",
    "class TimeRNN(nn.Module):\n",
    "    def __init__(self,bat_size,in_features,h_size,layer_amnt):\n",
    "        super(TimeRNN,self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.batch_sz = bat_size\n",
    "        self.in_features = in_features\n",
    "        self.h_size = h_size\n",
    "        self.layer_amnt = layer_amnt\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=self.in_features,\n",
    "                             hidden_size=self.h_size,\n",
    "                             num_layers=self.layer_amnt,\n",
    "                             bias=True,\n",
    "                             batch_first=False,\n",
    "                             dropout=0,\n",
    "                             bidirectional=False)\n",
    "        self.fc1 = nn.Linear(in_features=1,out_features=1)\n",
    "    def init_hidden(self):\n",
    "        \"\"\"Intialize/re-init the hidden and cell states. \n",
    "        The hidden state acts as the memory of the RNN \n",
    "        which gets passed from one unit to another. \n",
    "        h_i = f(h_i + in)\n",
    "\n",
    "        Intializing with 0s\n",
    "        \"\"\"\n",
    "        #print('layer size =\\t', self.layer_amnt)\n",
    "        #print('bat_size =\\t', self.batch_sz)\n",
    "        #print('hidden size =\\t',self.h_size)\n",
    "        return (torch.zeros(self.layer_amnt,self.batch_sz,self.h_size),\n",
    "                torch.zeros(self.layer_amnt,self.batch_sz,self.h_size))\n",
    "    def forward(self,x):\n",
    "        x = x.unsqueeze(0)\n",
    "        hidden_init = self.init_hidden()\n",
    "        h0 = hidden_init[0].to(self.device)\n",
    "        c0 = hidden_init[1].to(self.device)\n",
    "        x,hidden = self.lstm1( x,(h0,c0))\n",
    "        x = F.leaky_relu(self.fc1(x[-1].view(self.batch_sz,-1)))\n",
    "        return x\n",
    "\n",
    "class Inferencer(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def open_model(self,location):\n",
    "        model = TimeRNN(bat_size=1,in_features=3,h_size=1,layer_amnt=1)\n",
    "        model.load_state_dict(torch.load(location))\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def un_normalize(self,norm_val,min_val,max_val,typelist=None):\n",
    "        if(typelist):\n",
    "            for idx,item in enumerate(norm_val):\n",
    "                new_val = item * (max_val - min_val) + min_val\n",
    "                norm_val[idx] = new_val\n",
    "            return norm_val\n",
    "        else:\n",
    "            return norm_val * (max_val - min_val) + min_val \n",
    "\n",
    "    def inference(self,value, normalize_method, model,minimum_price,maximum_price):\n",
    "        value = np.array(value)\n",
    "        predictions = []\n",
    "        for sample in value:\n",
    "            sample = np.array(sample).reshape(1,-1)\n",
    "            example = torch.tensor(normalize_method.transform(sample)).float()\n",
    "            \n",
    "            if(str(device) == 'cuda'):\n",
    "                example = example.to(device)\n",
    "\n",
    "            output = model(example)\n",
    "            output_unnorm = self.un_normalize(norm_val=output.detach(),min_val=minimum_price,max_val=maximum_price)\n",
    "            predictions.append(output_unnorm)\n",
    "        return predictions\n",
    "\n",
    "    def fetch_latest_BTC_JSON(self):\n",
    "        \"\"\"Fetch the latest JSON data\"\"\"\n",
    "        API_LINK = 'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey=SAITMI5ZUMGEKGKY'\n",
    "        page = requests.get(API_LINK).json()\n",
    "        return page\n",
    "    def parse_alphaV_JSON(self,raw_data):\n",
    "        # Remove meta data for now\n",
    "        raw_data.pop('Meta Data',None)\n",
    "        # Remove key name\n",
    "        df = pd.DataFrame.from_dict(raw_data['Time Series (Digital Currency Daily)'],dtype=float)\n",
    "        # Flip dates as columns into rows\n",
    "        df = df.transpose()\n",
    "        return df\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    inf = Inferencer()\n",
    "    model_path = Model.get_model_path(model_name='price_predictor.pt')\n",
    "    #print(model_path)\n",
    "    #model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model = inf.open_model(location=model_path)\n",
    "    #model.eval()\n",
    "    \n",
    "def preprocess(input_data):\n",
    "    # convert the JSON data into the tensor input\n",
    "    return torch.tensor(input_data).float()\n",
    "\n",
    "def postprocess(result):\n",
    "    \n",
    "    result = np.array(result).item()\n",
    "    \n",
    "    inf = Inferencer()\n",
    "    \n",
    "    raw_data = inf.fetch_latest_BTC_JSON()\n",
    "    df = inf.parse_alphaV_JSON(raw_data=raw_data)\n",
    "    prices = np.array(df['4a. close (USD)'].tolist())\n",
    "    data_df_temp = df.drop(labels=['1a. open (USD)','1b. open (USD)','2b. high (USD)','3b. low (USD)','4a. close (USD)','4b. close (USD)','6. market cap (USD)'],axis=1)\n",
    "    minmax_2 = preprocessing.MinMaxScaler()\n",
    "    data_df_temp = pd.DataFrame(minmax_2.fit_transform(data_df_temp), columns=data_df_temp.columns)\n",
    "\n",
    "    minimum_price = np.min(prices)\n",
    "    maximum_price = np.max(prices)\n",
    "\n",
    "    res = inf.un_normalize(norm_val=result,min_val=minimum_price,max_val=maximum_price)\n",
    "    return res\n",
    "\n",
    "def run(input_data_json):\n",
    "    try:\n",
    "        start = time.time()   # start timer\n",
    "        input_data = preprocess(input_data_json) \n",
    "        #result = session.run([], {input_name: input_data})\n",
    "        output = model(input_data)\n",
    "        res = postprocess(output.detach())\n",
    "        end = time.time()     # stop timer\n",
    "        return {\"result\": res,\"time\": end - start}\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return {\"error\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': 11965.685513139926, 'time': 1.31931471824646}\n"
     ]
    }
   ],
   "source": [
    "test_sample = [[8700,11080,25000]]\n",
    "\n",
    "# test = preprocess(test_sample)\n",
    "# print(test)\n",
    "\n",
    "# test = postprocess([[0.2312]])\n",
    "# print(test)\n",
    "\n",
    "init()\n",
    "res = run(test_sample)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
