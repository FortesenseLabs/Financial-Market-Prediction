{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.53\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: crypto2\n",
      "Azure region: eastus2\n",
      "Resource group: crypto_prediction\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model =  Model(workspace=Workspace.create(name='crypto2', subscription_id='509b3593-2de3-40ce-a6b8-a838635aecb6', resource_group='crypto_prediction'), name=price_predictor_onnx, id=price_predictor_onnx:1, version=1, tags={'onnx': 'demo'}, properties={})\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "# model = Model.register(model_path='outputs/price_predictor.onnx',\n",
    "#                       model_name='price_predictor_onnx',\n",
    "#                       tags={'onnx':'demo'},\n",
    "#                       description='price prediction in torch onnx model',\n",
    "#                       workspace=ws\n",
    "#                       )\n",
    "\n",
    "\n",
    "model = Model(name='price_predictor_onnx',workspace=ws)\n",
    "print('Registered model = ', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'price_predictor_onnx': Model(workspace=Workspace.create(name='crypto2', subscription_id='509b3593-2de3-40ce-a6b8-a838635aecb6', resource_group='crypto_prediction'), name=price_predictor_onnx, id=price_predictor_onnx:1, version=1, tags={'onnx': 'demo'}, properties={})}\n",
      "Name price_predictor_onnx \tVersion: 1 \tDescription: price prediction in torch onnx model {'onnx': 'demo'}\n"
     ]
    }
   ],
   "source": [
    "models = ws.models\n",
    "print(models)\n",
    "\n",
    "for name,m in models.items():\n",
    "    print('Name',name,'\\tVersion:',m.version,'\\tDescription:',m.description,m.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the Score and Environment Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from azureml.core.model import Model\n",
    "import numpy as np    # we're going to use numpy to process input and output data\n",
    "import onnxruntime    # to inference ONNX models, we use the ONNX Runtime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Inferencer(object):\n",
    "    def __init__(self):\n",
    "        self.model = self.open_model()\n",
    "    \n",
    "    def open_model(self):\n",
    "        model = TimeRNN(bat_size=1,in_features=3,h_size=1,layer_amnt=1)\n",
    "        model.load_state_dict(torch.load(config['model_save_loc']))\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def un_normalize(self,norm_val,min_val,max_val,typelist=None):\n",
    "        if(typelist):\n",
    "            for idx,item in enumerate(norm_val):\n",
    "                new_val = item * (max_val - min_val) + min_val\n",
    "                norm_val[idx] = new_val\n",
    "            return norm_val\n",
    "        else:\n",
    "            return norm_val * (max_val - min_val) + min_val \n",
    "\n",
    "    def inference(self,value, normalize_method, model,minimum_price,maximum_price):\n",
    "        value = np.array(value)\n",
    "        predictions = []\n",
    "        for sample in value:\n",
    "            sample = np.array(sample).reshape(1,-1)\n",
    "            example = torch.tensor(normalize_method.transform(sample)).float()\n",
    "            \n",
    "            if(str(device) == 'cuda'):\n",
    "                example = example.to(device)\n",
    "\n",
    "            output = model(example)\n",
    "            output_unnorm = self.un_normalize(norm_val=output.detach(),min_val=minimum_price,max_val=maximum_price)\n",
    "            predictions.append(output_unnorm)\n",
    "        return predictions\n",
    "\n",
    "    def fetch_latest_BTC_JSON(self):\n",
    "        \"\"\"Fetch the latest JSON data\"\"\"\n",
    "        API_LINK = 'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey=SAITMI5ZUMGEKGKY'\n",
    "        page = requests.get(API_LINK).json()\n",
    "        return page\n",
    "    def parse_alphaV_JSON(self,raw_data):\n",
    "        # Remove meta data for now\n",
    "        raw_data.pop('Meta Data',None)\n",
    "        # Remove key name\n",
    "        df = pd.DataFrame.from_dict(raw_data['Time Series (Digital Currency Daily)'],dtype=float)\n",
    "        # Flip dates as columns into rows\n",
    "        df = df.transpose()\n",
    "        return df\n",
    "\n",
    "\n",
    "def init():\n",
    "    global session\n",
    "    model = Model.get_model_path(model_name='price_predictor')\n",
    "    session = onnxruntime.InferenceSession(model)\n",
    "\n",
    "def preprocess(input_data_json):\n",
    "    # convert the JSON data into the tensor input\n",
    "    return np.array(json.loads(input_data_json)['data']).astype('float32')\n",
    "\n",
    "def postprocess(result):\n",
    "    \n",
    "    inf = Inferencer()\n",
    "    \n",
    "    raw_data = inf.fetch_latest_BTC_JSON()\n",
    "    df = inf.parse_alphaV_JSON(raw_data=raw_data)\n",
    "    prices = np.array(df['4a. close (USD)'].tolist())\n",
    "    data_df_temp = df.drop(labels=['1a. open (USD)','1b. open (USD)','2b. high (USD)','3b. low (USD)','4a. close (USD)','4b. close (USD)','6. market cap (USD)'],axis=1)\n",
    "    minmax_2 = preprocessing.MinMaxScaler()\n",
    "    data_df_temp = pd.DataFrame(minmax_2.fit_transform(data_df_temp), columns=data_df_temp.columns)\n",
    "\n",
    "    minimum_price = np.min(prices)\n",
    "    maximum_price = np.max(prices)   \n",
    "    res = un_normalize(norm_val=result,min_val=minimum_price,max_val=maximum_price)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def run(input_data_json):\n",
    "    try:\n",
    "        start = time.time()   # start timer\n",
    "        input_data = preprocess(input_data_json)\n",
    "        input_name = session.get_inputs()[0].name  # get the id of the first input of the model   \n",
    "        result = session.run([], {input_name: input_data})\n",
    "        end = time.time()     # stop timer\n",
    "        return {\"result\": postprocess(result),\"time\": end - start}\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return {\"error\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the Environment File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=[\"numpy\",\n",
    "                                               \"onnxruntime\",\n",
    "                                               \"azureml-core\",\n",
    "                                               \"torch\",\"pyyaml\",\n",
    "                                               \"pandas\",\n",
    "                                               \"scikit-learn\"])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create container Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.......................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image onnxpriceprediction:1, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.model import Model\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  description = \"Price Prediction ONNX\",\n",
    "                                                  tags = {\"demo\": \"onnx\"}\n",
    "                                                 )\n",
    "\n",
    "\n",
    "image = ContainerImage.create(name = \"onnxpriceprediction\",\n",
    "                              models = [model],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_config.base_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://crypto25993529562.blob.core.windows.net/azureml/ImageLogs/f73bba5e-9c5f-4cd1-b86e-58598e011555/build.log?sv=2018-03-28&sr=b&sig=U22K7hqEL7FcHYg%2BrRVNgjIl4e6Jey%2BsSayA5YZfZ5s%3D&st=2019-08-02T08%3A10%3A49Z&se=2019-09-01T08%3A15%3A49Z&sp=rl\n"
     ]
    }
   ],
   "source": [
    "print(image.image_build_log_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing, cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "# create the AKS service with GPU nodes\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.image import Image\n",
    "from azureml.core.model import Model\n",
    "\n",
    "gpu_aks_name = 'AKS-GPU'\n",
    "\n",
    "try:\n",
    "    gpu_aks_target = ComputeTarget(workspace=ws,name=gpu_aks_name)\n",
    "    print('Found existing, cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    prov_config = AksCompute.provisioning_configuration(vm_size='BASIC_A3',location='East US2')\n",
    "    gpu_aks_target = ComputeTarget.create(workspace=ws,\n",
    "                                         name=gpu_aks_name,\n",
    "                                         provisioning_configuration=prov_config\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AksCompute(workspace=Workspace.create(name='crypto2', subscription_id='509b3593-2de3-40ce-a6b8-a838635aecb6', resource_group='crypto_prediction'), name=AKS-GPU, id=/subscriptions/509b3593-2de3-40ce-a6b8-a838635aecb6/resourceGroups/crypto_prediction/providers/Microsoft.MachineLearningServices/workspaces/crypto2/computes/AKS-GPU, type=AKS, provisioning_state=Failed, location=eastus2, tags=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_aks_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_aks_config = AksWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                                    memory_gb=1,\n",
    "                                                    tags = {'demo': 'onnx'},\n",
    "                                                    description = 'web service for MNIST ONNX model',\n",
    "                                                   gpu_cores=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Received bad response from Model Management Service:\n",
      "Response Code: 400\n",
      "Headers: {'Date': 'Fri, 02 Aug 2019 08:49:17 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-ms-client-request-id': '1b8c6415179e402f99e604ffa4d70cd1', 'x-ms-client-session-id': '', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\n",
      "Content: b'{\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid\",\"details\":[{\"code\":\"ComputeResourceNotCreated\",\"message\":\"Compute resource with Id: AKS-GPU is not in Succeeded state. Compute provisioning state: Failed\"}]}'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "Received bad response from Model Management Service:\nResponse Code: 400\nHeaders: {'Date': 'Fri, 02 Aug 2019 08:49:17 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-ms-client-request-id': '1b8c6415179e402f99e604ffa4d70cd1', 'x-ms-client-session-id': '', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\nContent: b'{\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid\",\"details\":[{\"code\":\"ComputeResourceNotCreated\",\"message\":\"Compute resource with Id: AKS-GPU is not in Succeeded state. Compute provisioning state: Failed\"}]}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m_deploy_webservice\u001b[0;34m(workspace, name, webservice_payload, webservice_class)\u001b[0m\n\u001b[1;32m    449\u001b[0m                                             json=webservice_payload)\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://eastus2.modelmanagement.azureml.net/api/subscriptions/509b3593-2de3-40ce-a6b8-a838635aecb6/resourceGroups/crypto_prediction/providers/Microsoft.MachineLearningServices/workspaces/crypto2/services?api-version=2018-11-19",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-91289f2aacd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                               \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                               \u001b[0mdeployment_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_aks_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                               \u001b[0mdeployment_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_aks_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                                               )\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# gpu_aks_service.wait_for_deployment(show_output=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mdeploy_from_image\u001b[0;34m(workspace, name, image, deployment_config, deployment_target)\u001b[0m\n\u001b[1;32m    352\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_webservice_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/aks.py\u001b[0m in \u001b[0;36m_deploy\u001b[0;34m(workspace, name, image, deployment_config, deployment_target)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mdeployment_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mcreate_payload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAksWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_create_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deploy_webservice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_payload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAksWebservice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m_deploy_webservice\u001b[0;34m(workspace, name, webservice_payload, webservice_class)\u001b[0m\n\u001b[1;32m    454\u001b[0m                                       \u001b[0;34m'Headers: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                                       \u001b[0;34m'Content: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                                       logger=module_logger)\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             raise WebserviceException('Error occurred creating service:\\n'\n",
      "\u001b[0;31mWebserviceException\u001b[0m: Received bad response from Model Management Service:\nResponse Code: 400\nHeaders: {'Date': 'Fri, 02 Aug 2019 08:49:17 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-ms-client-request-id': '1b8c6415179e402f99e604ffa4d70cd1', 'x-ms-client-session-id': '', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\nContent: b'{\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid\",\"details\":[{\"code\":\"ComputeResourceNotCreated\",\"message\":\"Compute resource with Id: AKS-GPU is not in Succeeded state. Compute provisioning state: Failed\"}]}'"
     ]
    }
   ],
   "source": [
    "gpu_aks_service_name = 'gpu-aks-service'\n",
    "gpu_aks_service = Webservice.deploy_from_image(workspace=ws,\n",
    "                                              name=gpu_aks_service_name,\n",
    "                                              image=image,\n",
    "                                              deployment_config=gpu_aks_config,\n",
    "                                              deployment_target=gpu_aks_target\n",
    "                                              )\n",
    "# gpu_aks_service.wait_for_deployment(show_output=True)\n",
    "# print(gpu_aks_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
