{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yaml\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Basic multilayer perceptron subclass \n",
    "of three layers in PyTorch\n",
    "\"\"\"\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=5,out_features=32)\n",
    "        self.fc2 = nn.Linear(in_features=32,out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128,out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\"Forward pass definition\"\"\"\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TickerData(torch.utils.data.Dataset):\n",
    "    def __init__(self, table):\n",
    "        self.dataset = table\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"idx --> data pointer\"\"\"\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_btc_prices():\n",
    "    with open(\"../BTC_data.json\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def parse_alphaV_JSON(raw_data):\n",
    "    # Remove meta data for now\n",
    "    raw_data.pop('Meta Data',None)\n",
    "    # Remove key name\n",
    "    df = pd.DataFrame.from_dict(raw_data['Time Series (Digital Currency Daily)'],dtype=float)\n",
    "    # Flip dates as columns into rows\n",
    "    df = df.transpose()\n",
    "    return df\n",
    "\n",
    "def normalize():\n",
    "    pass\n",
    "\n",
    "\n",
    "def data_split(x_train,y_train):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_train,y_train,test_size=0.2,random_state=100,shuffle=False)\n",
    "        return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def un_normalize(norm_val,min_val,max_val):\n",
    "    return norm_val * (max_val - min_val) + min_val\n",
    "\n",
    "def train(model, x_data,y_data, original_prices):\n",
    "\n",
    "    prices = torch.tensor(original_prices)\n",
    "    max_price = torch.max(prices)\n",
    "    min_price = torch.min(prices)\n",
    "\n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #min_max_scaler.fit_transform(y_data)\n",
    "\n",
    "    # x_train, x_test, y_train, y_test = data_split(x_train,y_train)\n",
    "\n",
    "    # # Prep input data --> torch.float64\n",
    "    # x_train = torch.from_numpy(x_train)\n",
    "    # y_train = torch.from_numpy(y_train)\n",
    "\n",
    "    # print(x_train.dtype)\n",
    "    # print(y_train.dtype)\n",
    "    # print(x_test.shape)\n",
    "    # print(x_test.shape)\n",
    "\n",
    "    print('----Dataset Prep----')\n",
    "    x_train, x_test, y_train, y_test = data_split(x_data,y_data)\n",
    "    train_tensorDataset = torch.utils.data.TensorDataset(torch.from_numpy(x_train),torch.from_numpy(y_train))\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_tensorDataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    test_tensorDataset = torch.utils.data.TensorDataset(torch.Tensor(x_test),torch.Tensor(y_test))\n",
    "    test_data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_tensorDataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    print('-- Model Architecture --')\n",
    "    print(model)\n",
    "\n",
    "    # -- Since we are predicting prices --> mean squared error is our loss function\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    # -- Optimizer --> Adam generally works best\n",
    "    # TODO: choose a better learning rate later\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    total_loss = 0\n",
    "    losses = []\n",
    "    for epoch in (range(100)):\n",
    "        for i, (examples,labels) in tqdm(enumerate(train_data_loader)):\n",
    "\n",
    "            #print(examples , \" ----- \" , labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_predictions = model(examples.float())\n",
    "            loss = loss_func(y_predictions.float(),labels.float())\n",
    "\n",
    "            total_loss += loss.data\n",
    "\n",
    "            # back-prop to update the weights\n",
    "            loss.backward()\n",
    "            # optimizer steps based on lr\n",
    "            optimizer.step()\n",
    "\n",
    "            y_preds = y_predictions.detach().numpy()\n",
    "            y_preds = torch.tensor(y_preds)\n",
    "            #print(y_preds.shape)\n",
    "            test = un_normalize(y_preds, min_price, max_price)\n",
    "            #print(\"---> \", test)\n",
    "            #break\n",
    "\n",
    "        print ('Epoch [{}/{}], Loss: {}'.format(epoch+1, 100, loss.data))\n",
    "        #print(list(model.parameters()))\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        losses.append(loss.data)\n",
    "    return losses, test_data_loader, loss_func, model, min_price, max_price\n",
    "\n",
    "\n",
    "def table_edit(dataframe):\n",
    "    dataframe = dataframe.drop(labels=['1b. open (USD)','2b. high (USD)','3b. low (USD)','4b. close (USD)'],axis=1)\n",
    "    table_col_order = ['1a. open (USD)','2a. high (USD)','3a. low (USD)','5. volume','6. market cap (USD)','4a. close (USD)']\n",
    "    dataframe = dataframe[table_col_order]\n",
    "    return dataframe\n",
    "\n",
    "def loss_visualize(loss_tensor):\n",
    "    losses = np.array(loss_tensor)\n",
    "    print(losses)\n",
    "    \n",
    "    plt.plot(losses)\n",
    "    \n",
    "def validation_test(test_dataloader, criterion, model, norm_min, norm_max):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for (examples, labels) in test_dataloader:\n",
    "        output = model.forward(examples)\n",
    "        \n",
    "        un_normed_outputs = un_normalize(output, norm_min,norm_max)\n",
    "        loss = criterion(output, labels).item()\n",
    "        test_loss += loss\n",
    "        \n",
    "        #ps = torch.exp(output)\n",
    "        #equality = (labels.data == ps.max(dim=1)[1])\n",
    "        #accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "        print('output --> ', un_normed_outputs, ' loss --> ', loss)\n",
    "        \n",
    "    return test_loss, accuracy\n",
    "    \n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:00, 265.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Dataset Prep----\n",
      "-- Model Architecture --\n",
      "MLP(\n",
      "  (fc1): Linear(in_features=5, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 401.29it/s]\n",
      "31it [00:00, 304.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.0007391194230876863\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 434.88it/s]\n",
      "26it [00:00, 256.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Loss: 0.0007416089647449553\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:04, 381.36it/s]\n",
      "37it [00:00, 366.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Loss: 0.001001856871880591\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 432.71it/s]\n",
      "40it [00:00, 394.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Loss: 9.330649390904e-07\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 416.36it/s]\n",
      "39it [00:00, 386.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 3.034478822883102e-06\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 429.27it/s]\n",
      "37it [00:00, 365.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Loss: 0.00040731727494858205\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 426.54it/s]\n",
      "44it [00:00, 439.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Loss: 0.00021615471632685512\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 423.75it/s]\n",
      "43it [00:00, 426.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Loss: 8.537378562323283e-06\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 440.07it/s]\n",
      "42it [00:00, 416.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Loss: 1.0406723482958569e-08\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 428.74it/s]\n",
      "42it [00:00, 413.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.00038808141835033894\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 408.05it/s]\n",
      "42it [00:00, 416.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Loss: 0.00021135836141183972\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 407.35it/s]\n",
      "33it [00:00, 328.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Loss: 2.055964432656765e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 427.15it/s]\n",
      "38it [00:00, 378.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Loss: 0.00017292032134719193\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 449.54it/s]\n",
      "37it [00:00, 360.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Loss: 0.00021964592451695353\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:04, 379.90it/s]\n",
      "30it [00:00, 298.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Loss: 3.936326174880378e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:04, 354.75it/s]\n",
      "37it [00:00, 358.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Loss: 0.00017706607468426228\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 399.44it/s]\n",
      "35it [00:00, 336.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Loss: 3.5227185435360298e-06\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 387.54it/s]\n",
      "57it [00:00, 567.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Loss: 7.378064037766308e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 442.16it/s]\n",
      "44it [00:00, 421.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Loss: 3.93636328226421e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 397.58it/s]\n",
      "35it [00:00, 347.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Loss: 9.978177695302293e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 426.92it/s]\n",
      "47it [00:00, 459.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Loss: 0.0004012459539808333\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 438.15it/s]\n",
      "44it [00:00, 433.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Loss: 0.0006318122032098472\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 437.76it/s]\n",
      "36it [00:00, 359.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Loss: 8.937721577240154e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 443.96it/s]\n",
      "47it [00:00, 469.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Loss: 0.00013701147690881044\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 425.42it/s]\n",
      "48it [00:00, 476.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Loss: 0.0006844283198006451\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 446.75it/s]\n",
      "46it [00:00, 456.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Loss: 0.0003425753675401211\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 421.20it/s]\n",
      "48it [00:00, 472.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Loss: 0.00012823878205381334\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 437.19it/s]\n",
      "48it [00:00, 479.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Loss: 0.0008013835758902133\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 447.32it/s]\n",
      "36it [00:00, 355.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Loss: 0.0005950079066678882\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 450.93it/s]\n",
      "37it [00:00, 369.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Loss: 3.2565720175625756e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 449.66it/s]\n",
      "48it [00:00, 471.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Loss: 0.0008680802420713007\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 448.32it/s]\n",
      "45it [00:00, 415.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Loss: 0.00026239771977998316\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 437.08it/s]\n",
      "38it [00:00, 376.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Loss: 0.0008287575328722596\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 437.35it/s]\n",
      "42it [00:00, 418.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Loss: 0.000769841717556119\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 416.73it/s]\n",
      "38it [00:00, 378.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Loss: 0.0011483246926218271\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 440.83it/s]\n",
      "40it [00:00, 393.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Loss: 0.0002665794745553285\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 431.48it/s]\n",
      "42it [00:00, 419.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Loss: 0.000831359182484448\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 397.93it/s]\n",
      "49it [00:00, 480.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Loss: 0.0002591616939753294\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 415.29it/s]\n",
      "44it [00:00, 434.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Loss: 0.00040505407378077507\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 437.24it/s]\n",
      "38it [00:00, 376.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Loss: 0.0012920921435579658\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 428.47it/s]\n",
      "45it [00:00, 446.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Loss: 0.0008776069735176861\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 412.64it/s]\n",
      "40it [00:00, 396.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Loss: 0.00017846474656835198\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 424.93it/s]\n",
      "40it [00:00, 395.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Loss: 0.0008822145755402744\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 422.92it/s]\n",
      "38it [00:00, 375.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Loss: 0.00022339045244734734\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 438.08it/s]\n",
      "47it [00:00, 464.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Loss: 0.0007838296005502343\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 438.83it/s]\n",
      "34it [00:00, 337.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Loss: 0.001162181724794209\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 425.49it/s]\n",
      "46it [00:00, 453.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Loss: 0.0007740663131698966\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 445.63it/s]\n",
      "44it [00:00, 438.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Loss: 0.00018138374434784055\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 447.25it/s]\n",
      "44it [00:00, 438.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Loss: 0.0004734179237857461\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 456.08it/s]\n",
      "39it [00:00, 389.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Loss: 0.0001957980712177232\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 429.11it/s]\n",
      "47it [00:00, 403.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Loss: 7.608848682139069e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 393.25it/s]\n",
      "40it [00:00, 390.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Loss: 4.097359487786889e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 407.48it/s]\n",
      "46it [00:00, 453.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Loss: 0.00017754068539943546\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:04, 358.00it/s]\n",
      "20it [00:00, 197.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Loss: 0.00014114314399193972\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 396.57it/s]\n",
      "48it [00:00, 473.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100], Loss: 0.0002512000792194158\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 438.88it/s]\n",
      "43it [00:00, 423.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Loss: 0.00019378490105737\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 445.18it/s]\n",
      "42it [00:00, 414.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Loss: 0.0002633853873703629\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 433.92it/s]\n",
      "43it [00:00, 429.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Loss: 0.0001604528952157125\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:04, 373.55it/s]\n",
      "33it [00:00, 328.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Loss: 0.0001953671162482351\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 392.13it/s]\n",
      "37it [00:00, 366.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Loss: 0.000156633643200621\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 417.43it/s]\n",
      "42it [00:00, 409.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Loss: 0.00020652329840231687\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 437.25it/s]\n",
      "31it [00:00, 305.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100], Loss: 0.00019896341837011278\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 400.65it/s]\n",
      "46it [00:00, 454.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Loss: 0.00016450845578219742\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 430.24it/s]\n",
      "44it [00:00, 437.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100], Loss: 0.0001005895683192648\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 427.48it/s]\n",
      "42it [00:00, 419.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Loss: 0.00011529152834555134\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 428.95it/s]\n",
      "37it [00:00, 365.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Loss: 0.00012889638310298324\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 430.21it/s]\n",
      "46it [00:00, 453.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100], Loss: 5.170537042431533e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:04, 381.21it/s]\n",
      "46it [00:00, 453.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100], Loss: 2.0945482901879586e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 435.01it/s]\n",
      "36it [00:00, 346.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100], Loss: 3.4367556509096175e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 425.44it/s]\n",
      "34it [00:00, 336.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100], Loss: 4.217301102471538e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 429.70it/s]\n",
      "45it [00:00, 434.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100], Loss: 0.0001332224055659026\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 434.72it/s]\n",
      "48it [00:00, 477.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100], Loss: 4.56082088930998e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 449.26it/s]\n",
      "35it [00:00, 349.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], Loss: 2.746284008026123e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 427.32it/s]\n",
      "38it [00:00, 376.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Loss: 3.622508666012436e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 434.97it/s]\n",
      "52it [00:00, 518.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Loss: 1.3331708942132536e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 455.15it/s]\n",
      "44it [00:00, 430.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100], Loss: 4.290658762329258e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 421.32it/s]\n",
      "46it [00:00, 453.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100], Loss: 5.525609230971895e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 440.38it/s]\n",
      "48it [00:00, 475.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100], Loss: 3.347988604218699e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 446.14it/s]\n",
      "51it [00:00, 503.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100], Loss: 1.9844901544274762e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 435.57it/s]\n",
      "37it [00:00, 367.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100], Loss: 1.5649622582714073e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 438.46it/s]\n",
      "49it [00:00, 486.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Loss: 1.7359090634272434e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 438.29it/s]\n",
      "47it [00:00, 462.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Loss: 1.4965909940656275e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 443.69it/s]\n",
      "50it [00:00, 492.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100], Loss: 1.5394129150081426e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 454.42it/s]\n",
      "46it [00:00, 450.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100], Loss: 1.9241248082835227e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 410.95it/s]\n",
      "38it [00:00, 378.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100], Loss: 4.9323916755383834e-06\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 433.11it/s]\n",
      "48it [00:00, 472.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100], Loss: 1.3008979294681922e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 452.97it/s]\n",
      "35it [00:00, 349.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100], Loss: 2.8283828214625828e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 443.53it/s]\n",
      "52it [00:00, 512.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Loss: 2.305451562278904e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 456.64it/s]\n",
      "48it [00:00, 477.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100], Loss: 1.687869917077478e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 448.50it/s]\n",
      "51it [00:00, 502.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100], Loss: 1.7116079106926918e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 435.05it/s]\n",
      "51it [00:00, 505.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100], Loss: 2.5037816158146597e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 445.61it/s]\n",
      "48it [00:00, 476.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100], Loss: 3.6489604099188e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 444.44it/s]\n",
      "50it [00:00, 492.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Loss: 1.7011192539939657e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 427.25it/s]\n",
      "43it [00:00, 429.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100], Loss: 6.648195994785056e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 416.51it/s]\n",
      "46it [00:00, 452.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100], Loss: 3.8466434489237145e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 446.95it/s]\n",
      "50it [00:00, 497.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100], Loss: 3.818231198238209e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 444.98it/s]\n",
      "47it [00:00, 462.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Loss: 3.147665847791359e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 440.14it/s]\n",
      "39it [00:00, 389.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Loss: 1.82254116225522e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:03, 393.90it/s]\n",
      "32it [00:00, 303.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100], Loss: 2.3367520043393597e-05\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1530it [00:04, 373.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 1.5326384527725168e-05\n",
      "-----------------------------------------------------------------------------\n",
      "[7.39119423e-04 7.41608965e-04 1.00185687e-03 9.33064939e-07\n",
      " 3.03447882e-06 4.07317275e-04 2.16154716e-04 8.53737856e-06\n",
      " 1.04067235e-08 3.88081418e-04 2.11358361e-04 2.05596443e-05\n",
      " 1.72920321e-04 2.19645925e-04 3.93632617e-05 1.77066075e-04\n",
      " 3.52271854e-06 7.37806404e-05 3.93636328e-05 9.97817770e-05\n",
      " 4.01245954e-04 6.31812203e-04 8.93772158e-05 1.37011477e-04\n",
      " 6.84428320e-04 3.42575368e-04 1.28238782e-04 8.01383576e-04\n",
      " 5.95007907e-04 3.25657202e-05 8.68080242e-04 2.62397720e-04\n",
      " 8.28757533e-04 7.69841718e-04 1.14832469e-03 2.66579475e-04\n",
      " 8.31359182e-04 2.59161694e-04 4.05054074e-04 1.29209214e-03\n",
      " 8.77606974e-04 1.78464747e-04 8.82214576e-04 2.23390452e-04\n",
      " 7.83829601e-04 1.16218172e-03 7.74066313e-04 1.81383744e-04\n",
      " 4.73417924e-04 1.95798071e-04 7.60884868e-05 4.09735949e-05\n",
      " 1.77540685e-04 1.41143144e-04 2.51200079e-04 1.93784901e-04\n",
      " 2.63385387e-04 1.60452895e-04 1.95367116e-04 1.56633643e-04\n",
      " 2.06523298e-04 1.98963418e-04 1.64508456e-04 1.00589568e-04\n",
      " 1.15291528e-04 1.28896383e-04 5.17053704e-05 2.09454829e-05\n",
      " 3.43675565e-05 4.21730110e-05 1.33222406e-04 4.56082089e-05\n",
      " 2.74628401e-05 3.62250867e-05 1.33317089e-05 4.29065876e-05\n",
      " 5.52560923e-05 3.34798860e-05 1.98449015e-05 1.56496226e-05\n",
      " 1.73590906e-05 1.49659099e-05 1.53941292e-05 1.92412481e-05\n",
      " 4.93239168e-06 1.30089793e-05 2.82838282e-05 2.30545156e-05\n",
      " 1.68786992e-05 1.71160791e-05 2.50378162e-05 3.64896041e-05\n",
      " 1.70111925e-05 6.64819599e-05 3.84664345e-05 3.81823120e-05\n",
      " 3.14766585e-05 1.82254116e-05 2.33675200e-05 1.53263845e-05]\n",
      "output -->  tensor([[7532.3970]], grad_fn=<AddBackward0>)  loss -->  1.8591754269436933e-06\n",
      "output -->  tensor([[6922.7148]], grad_fn=<AddBackward0>)  loss -->  6.494067929452285e-05\n",
      "output -->  tensor([[6845.4932]], grad_fn=<AddBackward0>)  loss -->  6.388282145053381e-06\n",
      "output -->  tensor([[6735.8438]], grad_fn=<AddBackward0>)  loss -->  5.6956174375955015e-05\n",
      "output -->  tensor([[6565.5522]], grad_fn=<AddBackward0>)  loss -->  0.00014716057921759784\n",
      "output -->  tensor([[6616.8975]], grad_fn=<AddBackward0>)  loss -->  6.088032478146488e-06\n",
      "output -->  tensor([[6603.0557]], grad_fn=<AddBackward0>)  loss -->  9.82663405011408e-05\n",
      "output -->  tensor([[6567.8921]], grad_fn=<AddBackward0>)  loss -->  5.109483936394099e-06\n",
      "output -->  tensor([[6586.2031]], grad_fn=<AddBackward0>)  loss -->  2.6720144887804054e-05\n",
      "output -->  tensor([[6631.5386]], grad_fn=<AddBackward0>)  loss -->  1.838607386162039e-05\n",
      "output -->  tensor([[6742.8755]], grad_fn=<AddBackward0>)  loss -->  5.564191241091976e-08\n",
      "output -->  tensor([[6704.5015]], grad_fn=<AddBackward0>)  loss -->  8.092777534329798e-06\n",
      "output -->  tensor([[6727.8481]], grad_fn=<AddBackward0>)  loss -->  1.5645092332761124e-08\n",
      "output -->  tensor([[6507.6357]], grad_fn=<AddBackward0>)  loss -->  0.0005305970553308725\n",
      "output -->  tensor([[6436.6865]], grad_fn=<AddBackward0>)  loss -->  0.00018017282127402723\n",
      "output -->  tensor([[6395.0269]], grad_fn=<AddBackward0>)  loss -->  0.00014539583935402334\n",
      "output -->  tensor([[6494.6538]], grad_fn=<AddBackward0>)  loss -->  0.00014648528303951025\n",
      "output -->  tensor([[6463.9146]], grad_fn=<AddBackward0>)  loss -->  0.0003742665285244584\n",
      "output -->  tensor([[6433.0381]], grad_fn=<AddBackward0>)  loss -->  0.00022856211580801755\n",
      "output -->  tensor([[6335.4268]], grad_fn=<AddBackward0>)  loss -->  0.0005246618529781699\n",
      "output -->  tensor([[6412.2261]], grad_fn=<AddBackward0>)  loss -->  0.0001289478241233155\n",
      "output -->  tensor([[6543.1230]], grad_fn=<AddBackward0>)  loss -->  5.952791980234906e-05\n",
      "output -->  tensor([[6536.9644]], grad_fn=<AddBackward0>)  loss -->  8.777119364822283e-05\n",
      "output -->  tensor([[6592.1538]], grad_fn=<AddBackward0>)  loss -->  1.4393335732165724e-06\n",
      "output -->  tensor([[6617.3267]], grad_fn=<AddBackward0>)  loss -->  2.590080111986026e-05\n",
      "output -->  tensor([[6626.3062]], grad_fn=<AddBackward0>)  loss -->  4.250094207236543e-06\n",
      "output -->  tensor([[6625.7217]], grad_fn=<AddBackward0>)  loss -->  1.1657465620373841e-05\n",
      "output -->  tensor([[6612.0151]], grad_fn=<AddBackward0>)  loss -->  1.6282174328807741e-06\n",
      "output -->  tensor([[6643.9922]], grad_fn=<AddBackward0>)  loss -->  4.625859219231643e-05\n",
      "output -->  tensor([[6720.1558]], grad_fn=<AddBackward0>)  loss -->  8.112348837130412e-07\n",
      "output -->  tensor([[6726.4980]], grad_fn=<AddBackward0>)  loss -->  8.790582342044218e-07\n",
      "output -->  tensor([[6601.0508]], grad_fn=<AddBackward0>)  loss -->  0.00019868186791427433\n",
      "output -->  tensor([[6560.0796]], grad_fn=<AddBackward0>)  loss -->  5.0856408051913604e-05\n",
      "output -->  tensor([[6514.7739]], grad_fn=<AddBackward0>)  loss -->  0.00020720396423712373\n",
      "output -->  tensor([[6498.3018]], grad_fn=<AddBackward0>)  loss -->  0.00016355728439521044\n",
      "output -->  tensor([[6451.2280]], grad_fn=<AddBackward0>)  loss -->  7.273176743183285e-05\n",
      "output -->  tensor([[6505.9668]], grad_fn=<AddBackward0>)  loss -->  4.955564145348035e-05\n",
      "output -->  tensor([[6616.8584]], grad_fn=<AddBackward0>)  loss -->  5.274474460748024e-05\n",
      "output -->  tensor([[6941.3818]], grad_fn=<AddBackward0>)  loss -->  0.0004332375538069755\n",
      "output -->  tensor([[7254.7734]], grad_fn=<AddBackward0>)  loss -->  5.235544085735455e-05\n",
      "output -->  tensor([[7333.5444]], grad_fn=<AddBackward0>)  loss -->  5.4498843383044004e-05\n",
      "output -->  tensor([[7325.1172]], grad_fn=<AddBackward0>)  loss -->  1.5330582527894876e-06\n",
      "output -->  tensor([[7332.3315]], grad_fn=<AddBackward0>)  loss -->  2.290479460498318e-05\n",
      "output -->  tensor([[7420.7573]], grad_fn=<AddBackward0>)  loss -->  6.859308143702947e-08\n",
      "output -->  tensor([[7411.6719]], grad_fn=<AddBackward0>)  loss -->  0.0002606674679554999\n",
      "output -->  tensor([[7714.1206]], grad_fn=<AddBackward0>)  loss -->  0.0013030680129304528\n",
      "output -->  tensor([[7919.6577]], grad_fn=<AddBackward0>)  loss -->  0.00018399882537778467\n",
      "output -->  tensor([[7804.2856]], grad_fn=<AddBackward0>)  loss -->  6.500553718069568e-05\n",
      "output -->  tensor([[7789.9761]], grad_fn=<AddBackward0>)  loss -->  0.00037460215389728546\n",
      "output -->  tensor([[7964.8071]], grad_fn=<AddBackward0>)  loss -->  0.00013747303455602378\n",
      "output -->  tensor([[7998.9517]], grad_fn=<AddBackward0>)  loss -->  0.0001226382446475327\n",
      "output -->  tensor([[7802.5210]], grad_fn=<AddBackward0>)  loss -->  0.00038777265581302345\n",
      "output -->  tensor([[7647.1348]], grad_fn=<AddBackward0>)  loss -->  3.0331888410728425e-05\n",
      "output -->  tensor([[7451.3965]], grad_fn=<AddBackward0>)  loss -->  6.85620034346357e-05\n",
      "output -->  tensor([[7506.9814]], grad_fn=<AddBackward0>)  loss -->  5.8869145505013876e-06\n",
      "output -->  tensor([[7324.0488]], grad_fn=<AddBackward0>)  loss -->  2.594966281321831e-05\n",
      "output -->  tensor([[7147.5283]], grad_fn=<AddBackward0>)  loss -->  4.8927417083177716e-05\n",
      "output -->  tensor([[7024.1519]], grad_fn=<AddBackward0>)  loss -->  1.076361513696611e-06\n",
      "output -->  tensor([[7029.6489]], grad_fn=<AddBackward0>)  loss -->  1.9410255845286883e-05\n",
      "output -->  tensor([[6897.9844]], grad_fn=<AddBackward0>)  loss -->  7.610304601257667e-05\n",
      "output -->  tensor([[6554.3560]], grad_fn=<AddBackward0>)  loss -->  0.00021715310867875814\n",
      "output -->  tensor([[6590.6953]], grad_fn=<AddBackward0>)  loss -->  4.927097961626714e-06\n",
      "output -->  tensor([[6549.4209]], grad_fn=<AddBackward0>)  loss -->  0.0004001339548267424\n",
      "output -->  tensor([[6518.4536]], grad_fn=<AddBackward0>)  loss -->  0.00016017215966712683\n",
      "output -->  tensor([[6530.8154]], grad_fn=<AddBackward0>)  loss -->  0.00010916960309259593\n",
      "output -->  tensor([[6556.9038]], grad_fn=<AddBackward0>)  loss -->  0.00021556272986344993\n",
      "output -->  tensor([[6430.2144]], grad_fn=<AddBackward0>)  loss -->  0.00014079283573664725\n",
      "output -->  tensor([[6525.1167]], grad_fn=<AddBackward0>)  loss -->  0.00015219861234072596\n",
      "output -->  tensor([[6559.4072]], grad_fn=<AddBackward0>)  loss -->  0.000151842919876799\n",
      "output -->  tensor([[6591.9580]], grad_fn=<AddBackward0>)  loss -->  4.5843592033634195e-07\n",
      "output -->  tensor([[6587.8853]], grad_fn=<AddBackward0>)  loss -->  7.77555542299524e-05\n",
      "output -->  tensor([[6575.9263]], grad_fn=<AddBackward0>)  loss -->  2.074030453513842e-05\n",
      "output -->  tensor([[6572.8608]], grad_fn=<AddBackward0>)  loss -->  0.000186377830686979\n",
      "output -->  tensor([[6573.4458]], grad_fn=<AddBackward0>)  loss -->  2.6859899662667885e-05\n",
      "output -->  tensor([[6584.9419]], grad_fn=<AddBackward0>)  loss -->  0.0001253327791346237\n",
      "output -->  tensor([[6584.8164]], grad_fn=<AddBackward0>)  loss -->  7.941058356664144e-06\n",
      "output -->  tensor([[6631.5581]], grad_fn=<AddBackward0>)  loss -->  1.0325784387532622e-05\n",
      "output -->  tensor([[6701.4102]], grad_fn=<AddBackward0>)  loss -->  5.932267413299996e-06\n",
      "output -->  tensor([[6657.8428]], grad_fn=<AddBackward0>)  loss -->  1.3870905604562722e-05\n",
      "output -->  tensor([[6798.8950]], grad_fn=<AddBackward0>)  loss -->  2.905197470681742e-05\n",
      "output -->  tensor([[7017.7632]], grad_fn=<AddBackward0>)  loss -->  1.2067827810824383e-05\n",
      "output -->  tensor([[7049.5723]], grad_fn=<AddBackward0>)  loss -->  2.457796028920711e-07\n",
      "output -->  tensor([[6937.1167]], grad_fn=<AddBackward0>)  loss -->  6.464435955422232e-06\n",
      "output -->  tensor([[7015.5884]], grad_fn=<AddBackward0>)  loss -->  2.635111741255969e-06\n",
      "output -->  tensor([[7134.7397]], grad_fn=<AddBackward0>)  loss -->  9.230464456777554e-06\n",
      "output -->  tensor([[7203.7402]], grad_fn=<AddBackward0>)  loss -->  1.4613143321184907e-05\n",
      "output -->  tensor([[7259.2427]], grad_fn=<AddBackward0>)  loss -->  4.337165648848895e-08\n",
      "output -->  tensor([[7313.3965]], grad_fn=<AddBackward0>)  loss -->  7.0563037297688425e-06\n",
      "output -->  tensor([[6913.8364]], grad_fn=<AddBackward0>)  loss -->  0.00011842809180961922\n",
      "output -->  tensor([[6594.3306]], grad_fn=<AddBackward0>)  loss -->  2.2310225176624954e-05\n",
      "output -->  tensor([[6584.9521]], grad_fn=<AddBackward0>)  loss -->  5.212840187596157e-05\n",
      "output -->  tensor([[6514.4141]], grad_fn=<AddBackward0>)  loss -->  0.000261631648754701\n",
      "output -->  tensor([[6502.8462]], grad_fn=<AddBackward0>)  loss -->  0.00015942094614729285\n",
      "output -->  tensor([[6521.3081]], grad_fn=<AddBackward0>)  loss -->  0.00011232399992877617\n",
      "output -->  tensor([[6526.5483]], grad_fn=<AddBackward0>)  loss -->  0.00015157861344050616\n",
      "output -->  tensor([[6516.6074]], grad_fn=<AddBackward0>)  loss -->  8.541397983208299e-05\n",
      "output -->  tensor([[6580.5005]], grad_fn=<AddBackward0>)  loss -->  1.814204551919829e-05\n",
      "output -->  tensor([[6599.6411]], grad_fn=<AddBackward0>)  loss -->  3.1163435778580606e-05\n",
      "output -->  tensor([[6584.9170]], grad_fn=<AddBackward0>)  loss -->  9.829319424170535e-06\n",
      "output -->  tensor([[6575.2056]], grad_fn=<AddBackward0>)  loss -->  1.4711969015479553e-05\n",
      "output -->  tensor([[6560.2266]], grad_fn=<AddBackward0>)  loss -->  0.00022276282834354788\n",
      "output -->  tensor([[6548.1421]], grad_fn=<AddBackward0>)  loss -->  0.0001020745694404468\n",
      "output -->  tensor([[6565.1606]], grad_fn=<AddBackward0>)  loss -->  7.329812069656327e-05\n",
      "output -->  tensor([[6589.5444]], grad_fn=<AddBackward0>)  loss -->  1.5968371371855028e-05\n",
      "output -->  tensor([[6697.1841]], grad_fn=<AddBackward0>)  loss -->  8.95137509360211e-06\n",
      "output -->  tensor([[6729.4058]], grad_fn=<AddBackward0>)  loss -->  1.491338252890273e-07\n",
      "output -->  tensor([[6688.6494]], grad_fn=<AddBackward0>)  loss -->  5.503256943484303e-07\n",
      "output -->  tensor([[6659.9663]], grad_fn=<AddBackward0>)  loss -->  9.370429324917495e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output -->  tensor([[6597.5327]], grad_fn=<AddBackward0>)  loss -->  6.75779883749783e-05\n",
      "output -->  tensor([[6586.5249]], grad_fn=<AddBackward0>)  loss -->  3.393528822925873e-05\n",
      "output -->  tensor([[6627.9951]], grad_fn=<AddBackward0>)  loss -->  8.710313522897195e-06\n",
      "output -->  tensor([[6743.4937]], grad_fn=<AddBackward0>)  loss -->  3.17662488669157e-05\n",
      "output -->  tensor([[6614.1348]], grad_fn=<AddBackward0>)  loss -->  2.628809170346358e-07\n",
      "output -->  tensor([[6621.8120]], grad_fn=<AddBackward0>)  loss -->  1.9835079001495615e-07\n",
      "output -->  tensor([[6626.9316]], grad_fn=<AddBackward0>)  loss -->  5.478896127897315e-06\n",
      "output -->  tensor([[6618.5586]], grad_fn=<AddBackward0>)  loss -->  1.5854484445299022e-05\n",
      "output -->  tensor([[6599.4878]], grad_fn=<AddBackward0>)  loss -->  3.212739829905331e-05\n",
      "output -->  tensor([[6610.9106]], grad_fn=<AddBackward0>)  loss -->  7.591756002511829e-06\n",
      "output -->  tensor([[6622.6953]], grad_fn=<AddBackward0>)  loss -->  4.868924463607982e-08\n",
      "output -->  tensor([[6608.0044]], grad_fn=<AddBackward0>)  loss -->  9.44210057696182e-07\n",
      "output -->  tensor([[6602.3799]], grad_fn=<AddBackward0>)  loss -->  3.1599171279594884e-07\n",
      "output -->  tensor([[6633.9512]], grad_fn=<AddBackward0>)  loss -->  1.361678755529283e-06\n",
      "output -->  tensor([[6631.6758]], grad_fn=<AddBackward0>)  loss -->  5.594721415036474e-07\n",
      "output -->  tensor([[6623.8501]], grad_fn=<AddBackward0>)  loss -->  5.793144282506546e-06\n",
      "output -->  tensor([[6561.1802]], grad_fn=<AddBackward0>)  loss -->  0.00029904910479672253\n",
      "output -->  tensor([[6493.7925]], grad_fn=<AddBackward0>)  loss -->  0.00016625535499770194\n",
      "output -->  tensor([[6470.2441]], grad_fn=<AddBackward0>)  loss -->  0.0001367039658362046\n",
      "output -->  tensor([[6504.6885]], grad_fn=<AddBackward0>)  loss -->  0.00013361139281187207\n",
      "output -->  tensor([[6557.6421]], grad_fn=<AddBackward0>)  loss -->  8.513187822245527e-06\n",
      "output -->  tensor([[6654.5684]], grad_fn=<AddBackward0>)  loss -->  4.193147105979733e-06\n",
      "output -->  tensor([[6614.8271]], grad_fn=<AddBackward0>)  loss -->  1.4764598745387048e-05\n",
      "output -->  tensor([[6604.8740]], grad_fn=<AddBackward0>)  loss -->  3.071618630201556e-05\n",
      "output -->  tensor([[6587.9697]], grad_fn=<AddBackward0>)  loss -->  5.644407428917475e-05\n",
      "output -->  tensor([[6572.0933]], grad_fn=<AddBackward0>)  loss -->  1.862144381448161e-05\n",
      "output -->  tensor([[6582.1191]], grad_fn=<AddBackward0>)  loss -->  1.7940015823114663e-05\n",
      "output -->  tensor([[6591.4614]], grad_fn=<AddBackward0>)  loss -->  4.1816496377578005e-05\n",
      "output -->  tensor([[6585.5718]], grad_fn=<AddBackward0>)  loss -->  2.855805360013619e-05\n",
      "output -->  tensor([[6592.7954]], grad_fn=<AddBackward0>)  loss -->  2.627739741001278e-05\n",
      "output -->  tensor([[6585.0923]], grad_fn=<AddBackward0>)  loss -->  4.326222187955864e-05\n",
      "output -->  tensor([[6584.4111]], grad_fn=<AddBackward0>)  loss -->  5.126144606037997e-05\n",
      "output -->  tensor([[6563.2764]], grad_fn=<AddBackward0>)  loss -->  3.833162190858275e-05\n",
      "output -->  tensor([[6567.0972]], grad_fn=<AddBackward0>)  loss -->  4.01993420382496e-05\n",
      "output -->  tensor([[6562.1816]], grad_fn=<AddBackward0>)  loss -->  0.00016914754814933985\n",
      "output -->  tensor([[6525.2642]], grad_fn=<AddBackward0>)  loss -->  0.00012708919530268759\n",
      "output -->  tensor([[6520.5762]], grad_fn=<AddBackward0>)  loss -->  9.080287418328226e-05\n",
      "output -->  tensor([[6540.3960]], grad_fn=<AddBackward0>)  loss -->  7.034775626379997e-05\n",
      "output -->  tensor([[6546.5879]], grad_fn=<AddBackward0>)  loss -->  6.190623389557004e-05\n",
      "output -->  tensor([[6525.9883]], grad_fn=<AddBackward0>)  loss -->  5.9704641898861155e-05\n",
      "output -->  tensor([[6548.0522]], grad_fn=<AddBackward0>)  loss -->  2.285062691953499e-05\n",
      "output -->  tensor([[6564.1362]], grad_fn=<AddBackward0>)  loss -->  4.017931496491656e-05\n",
      "output -->  tensor([[6576.7495]], grad_fn=<AddBackward0>)  loss -->  3.022169039468281e-05\n",
      "output -->  tensor([[6601.2744]], grad_fn=<AddBackward0>)  loss -->  1.6813868569443002e-05\n",
      "output -->  tensor([[6596.1470]], grad_fn=<AddBackward0>)  loss -->  5.897963637835346e-05\n",
      "output -->  tensor([[6571.3877]], grad_fn=<AddBackward0>)  loss -->  7.073472806951031e-05\n",
      "output -->  tensor([[6528.1938]], grad_fn=<AddBackward0>)  loss -->  4.4937256461707875e-05\n",
      "output -->  tensor([[6533.4097]], grad_fn=<AddBackward0>)  loss -->  4.4777178118238226e-05\n",
      "output -->  tensor([[6561.6826]], grad_fn=<AddBackward0>)  loss -->  9.350869368063286e-05\n",
      "output -->  tensor([[6546.1963]], grad_fn=<AddBackward0>)  loss -->  9.144524665316567e-05\n",
      "output -->  tensor([[6054.7261]], grad_fn=<AddBackward0>)  loss -->  0.0003182644722983241\n",
      "output -->  tensor([[5953.8574]], grad_fn=<AddBackward0>)  loss -->  0.0002555730170570314\n",
      "output -->  tensor([[5945.4224]], grad_fn=<AddBackward0>)  loss -->  0.00037476251600310206\n",
      "output -->  tensor([[5857.4580]], grad_fn=<AddBackward0>)  loss -->  0.00024358958762604743\n",
      "output -->  tensor([[5919.3115]], grad_fn=<AddBackward0>)  loss -->  0.0002554901293478906\n",
      "output -->  tensor([[5398.6704]], grad_fn=<AddBackward0>)  loss -->  0.000851899734698236\n",
      "output -->  tensor([[4617.3721]], grad_fn=<AddBackward0>)  loss -->  8.346661343239248e-05\n",
      "output -->  tensor([[4897.5981]], grad_fn=<AddBackward0>)  loss -->  0.00023637560661882162\n",
      "output -->  tensor([[4873.0342]], grad_fn=<AddBackward0>)  loss -->  0.0007418792229145765\n",
      "output -->  tensor([[4711.7695]], grad_fn=<AddBackward0>)  loss -->  0.00036882187123410404\n",
      "output -->  tensor([[4418.4604]], grad_fn=<AddBackward0>)  loss -->  0.0008445116691291332\n",
      "output -->  tensor([[4167.5430]], grad_fn=<AddBackward0>)  loss -->  6.197472248459235e-05\n",
      "output -->  tensor([[4116.6753]], grad_fn=<AddBackward0>)  loss -->  0.0003047138452529907\n",
      "output -->  tensor([[4116.8696]], grad_fn=<AddBackward0>)  loss -->  0.00024926059995777905\n",
      "output -->  tensor([[4421.3545]], grad_fn=<AddBackward0>)  loss -->  7.028178515611216e-05\n",
      "output -->  tensor([[4658.6587]], grad_fn=<AddBackward0>)  loss -->  0.0004009087278973311\n",
      "output -->  tensor([[4479.0337]], grad_fn=<AddBackward0>)  loss -->  0.0005904462886974216\n",
      "output -->  tensor([[4525.5781]], grad_fn=<AddBackward0>)  loss -->  0.0002974366070702672\n",
      "output -->  tensor([[4588.7700]], grad_fn=<AddBackward0>)  loss -->  0.0005655232816934586\n",
      "output -->  tensor([[4357.9380]], grad_fn=<AddBackward0>)  loss -->  0.0006307848379947245\n",
      "output -->  tensor([[4342.1489]], grad_fn=<AddBackward0>)  loss -->  0.000432800326962024\n",
      "output -->  tensor([[4250.4609]], grad_fn=<AddBackward0>)  loss -->  0.0006709801382385194\n",
      "output -->  tensor([[3958.1169]], grad_fn=<AddBackward0>)  loss -->  0.0005514705553650856\n",
      "output -->  tensor([[3709.1655]], grad_fn=<AddBackward0>)  loss -->  0.00023609436175320297\n",
      "output -->  tensor([[3840.5942]], grad_fn=<AddBackward0>)  loss -->  0.00035149644827470183\n",
      "output -->  tensor([[3978.3794]], grad_fn=<AddBackward0>)  loss -->  0.00035606889287009835\n",
      "output -->  tensor([[3947.0120]], grad_fn=<AddBackward0>)  loss -->  0.0005409255973063409\n",
      "output -->  tensor([[3819.4897]], grad_fn=<AddBackward0>)  loss -->  0.00043346709571778774\n",
      "output -->  tensor([[3835.7314]], grad_fn=<AddBackward0>)  loss -->  0.0003317449882160872\n",
      "output -->  tensor([[3726.9561]], grad_fn=<AddBackward0>)  loss -->  0.0004667463945224881\n",
      "output -->  tensor([[3618.5750]], grad_fn=<AddBackward0>)  loss -->  0.0003929318336304277\n",
      "output -->  tensor([[3557.3059]], grad_fn=<AddBackward0>)  loss -->  0.000270340358838439\n",
      "output -->  tensor([[3592.5740]], grad_fn=<AddBackward0>)  loss -->  0.00031412564567290246\n",
      "output -->  tensor([[3824.7593]], grad_fn=<AddBackward0>)  loss -->  0.0002120430435752496\n",
      "output -->  tensor([[3991.7278]], grad_fn=<AddBackward0>)  loss -->  0.0002258743770653382\n",
      "output -->  tensor([[4128.1963]], grad_fn=<AddBackward0>)  loss -->  0.00037125032395124435\n",
      "output -->  tensor([[4302.4170]], grad_fn=<AddBackward0>)  loss -->  6.411642243620008e-05\n",
      "output -->  tensor([[4377.3628]], grad_fn=<AddBackward0>)  loss -->  0.0006103896885178983\n",
      "output -->  tensor([[4326.0205]], grad_fn=<AddBackward0>)  loss -->  0.00023895307094790041\n",
      "output -->  tensor([[4408.0439]], grad_fn=<AddBackward0>)  loss -->  0.0004351570678409189\n",
      "output -->  tensor([[4522.0757]], grad_fn=<AddBackward0>)  loss -->  0.0005272276466712356\n",
      "output -->  tensor([[4317.5757]], grad_fn=<AddBackward0>)  loss -->  0.0006712241447530687\n",
      "output -->  tensor([[4209.0083]], grad_fn=<AddBackward0>)  loss -->  0.00032582724816165864\n",
      "output -->  tensor([[4118.2896]], grad_fn=<AddBackward0>)  loss -->  0.0005795267643406987\n",
      "output -->  tensor([[4212.0557]], grad_fn=<AddBackward0>)  loss -->  0.00020672719983849674\n",
      "output -->  tensor([[4228.9771]], grad_fn=<AddBackward0>)  loss -->  0.0004003444337286055\n",
      "output -->  tensor([[4230.1255]], grad_fn=<AddBackward0>)  loss -->  0.00033718111808411777\n",
      "output -->  tensor([[4174.2812]], grad_fn=<AddBackward0>)  loss -->  0.00048277535825036466\n",
      "output -->  tensor([[4140.8340]], grad_fn=<AddBackward0>)  loss -->  0.00020923289412166923\n",
      "output -->  tensor([[4270.5088]], grad_fn=<AddBackward0>)  loss -->  0.0002781215589493513\n",
      "output -->  tensor([[4245.8887]], grad_fn=<AddBackward0>)  loss -->  0.00042094083619304\n",
      "output -->  tensor([[4194.9307]], grad_fn=<AddBackward0>)  loss -->  0.0003042827302124351\n",
      "output -->  tensor([[4217.7124]], grad_fn=<AddBackward0>)  loss -->  0.0003690537123475224\n",
      "output -->  tensor([[4373.5596]], grad_fn=<AddBackward0>)  loss -->  0.0002305556699866429\n",
      "output -->  tensor([[4462.5957]], grad_fn=<AddBackward0>)  loss -->  0.000510044046677649\n",
      "output -->  tensor([[4481.5820]], grad_fn=<AddBackward0>)  loss -->  0.0005615401896648109\n",
      "output -->  tensor([[4451.6777]], grad_fn=<AddBackward0>)  loss -->  0.0004643742286134511\n",
      "output -->  tensor([[4162.3779]], grad_fn=<AddBackward0>)  loss -->  0.0006754922214895487\n",
      "output -->  tensor([[4060.4094]], grad_fn=<AddBackward0>)  loss -->  0.0004230425402056426\n",
      "output -->  tensor([[3996.5054]], grad_fn=<AddBackward0>)  loss -->  0.0003194991440977901\n",
      "output -->  tensor([[3931.2473]], grad_fn=<AddBackward0>)  loss -->  0.00042135734111070633\n",
      "output -->  tensor([[4020.7517]], grad_fn=<AddBackward0>)  loss -->  0.00027935553225688636\n",
      "output -->  tensor([[4026.9561]], grad_fn=<AddBackward0>)  loss -->  0.0004261591238901019\n",
      "output -->  tensor([[4021.4753]], grad_fn=<AddBackward0>)  loss -->  0.00037187247653491795\n",
      "output -->  tensor([[4004.8418]], grad_fn=<AddBackward0>)  loss -->  0.0002979204582516104\n",
      "output -->  tensor([[3997.5664]], grad_fn=<AddBackward0>)  loss -->  0.000329117028741166\n",
      "output -->  tensor([[4045.9841]], grad_fn=<AddBackward0>)  loss -->  0.00027464100276120007\n",
      "output -->  tensor([[4027.8667]], grad_fn=<AddBackward0>)  loss -->  0.0004893661825917661\n",
      "output -->  tensor([[3942.9890]], grad_fn=<AddBackward0>)  loss -->  0.00037450293893925846\n",
      "output -->  tensor([[3955.5923]], grad_fn=<AddBackward0>)  loss -->  0.00033657121821306646\n",
      "output -->  tensor([[4002.2043]], grad_fn=<AddBackward0>)  loss -->  0.00048324171802960336\n",
      "output -->  tensor([[3941.3303]], grad_fn=<AddBackward0>)  loss -->  0.00031114471494220197\n",
      "output -->  tensor([[3947.4805]], grad_fn=<AddBackward0>)  loss -->  0.00033011476625688374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output -->  tensor([[3972.5703]], grad_fn=<AddBackward0>)  loss -->  0.0003805994347203523\n",
      "output -->  tensor([[3928.8225]], grad_fn=<AddBackward0>)  loss -->  0.00032630134955979884\n",
      "output -->  tensor([[3895.6467]], grad_fn=<AddBackward0>)  loss -->  0.0005062248674221337\n",
      "output -->  tensor([[3792.4031]], grad_fn=<AddBackward0>)  loss -->  0.00033629516838118434\n",
      "output -->  tensor([[3824.9390]], grad_fn=<AddBackward0>)  loss -->  0.00032351654954254627\n",
      "output -->  tensor([[3840.2585]], grad_fn=<AddBackward0>)  loss -->  0.0004096549528185278\n",
      "output -->  tensor([[3818.2151]], grad_fn=<AddBackward0>)  loss -->  0.00031143336673267186\n",
      "output -->  tensor([[3819.9377]], grad_fn=<AddBackward0>)  loss -->  0.00026600901037454605\n",
      "output -->  tensor([[3805.3301]], grad_fn=<AddBackward0>)  loss -->  0.0003371220373082906\n",
      "output -->  tensor([[3801.3149]], grad_fn=<AddBackward0>)  loss -->  0.00032378730247728527\n",
      "output -->  tensor([[3772.5425]], grad_fn=<AddBackward0>)  loss -->  0.0002664549392648041\n",
      "output -->  tensor([[3770.8076]], grad_fn=<AddBackward0>)  loss -->  0.0003616347967181355\n",
      "output -->  tensor([[3729.8943]], grad_fn=<AddBackward0>)  loss -->  0.000311925308778882\n",
      "output -->  tensor([[3931.0701]], grad_fn=<AddBackward0>)  loss -->  0.0002013553457800299\n",
      "output -->  tensor([[3995.6453]], grad_fn=<AddBackward0>)  loss -->  0.0002957562101073563\n",
      "output -->  tensor([[4006.6941]], grad_fn=<AddBackward0>)  loss -->  0.00027681299252435565\n",
      "output -->  tensor([[4011.5879]], grad_fn=<AddBackward0>)  loss -->  0.00036693556467071176\n",
      "output -->  tensor([[4003.7234]], grad_fn=<AddBackward0>)  loss -->  0.00034591738949529827\n",
      "output -->  tensor([[3990.3787]], grad_fn=<AddBackward0>)  loss -->  0.00036491628270596266\n",
      "output -->  tensor([[3966.3262]], grad_fn=<AddBackward0>)  loss -->  0.00034450649400241673\n",
      "output -->  tensor([[3971.1489]], grad_fn=<AddBackward0>)  loss -->  0.00034999169292859733\n",
      "output -->  tensor([[3973.0183]], grad_fn=<AddBackward0>)  loss -->  0.0003399487177375704\n",
      "output -->  tensor([[4006.5161]], grad_fn=<AddBackward0>)  loss -->  0.00032422825461253524\n",
      "output -->  tensor([[4175.2290]], grad_fn=<AddBackward0>)  loss -->  0.00018988341616932303\n",
      "output -->  tensor([[4336.1826]], grad_fn=<AddBackward0>)  loss -->  0.0004063158412463963\n",
      "output -->  tensor([[4395.4126]], grad_fn=<AddBackward0>)  loss -->  0.0004249645571690053\n",
      "output -->  tensor([[4374.7749]], grad_fn=<AddBackward0>)  loss -->  0.00048512444482184947\n",
      "output -->  tensor([[4413.4072]], grad_fn=<AddBackward0>)  loss -->  0.00045819749357178807\n",
      "output -->  tensor([[4473.1875]], grad_fn=<AddBackward0>)  loss -->  0.0003012501692865044\n",
      "output -->  tensor([[4300.8530]], grad_fn=<AddBackward0>)  loss -->  0.0006552120321430266\n",
      "output -->  tensor([[4282.7349]], grad_fn=<AddBackward0>)  loss -->  0.0004309707728680223\n",
      "output -->  tensor([[4255.8857]], grad_fn=<AddBackward0>)  loss -->  0.00043024166370742023\n",
      "output -->  tensor([[4256.0332]], grad_fn=<AddBackward0>)  loss -->  0.00046470502275042236\n",
      "output -->  tensor([[4293.3101]], grad_fn=<AddBackward0>)  loss -->  0.0005178889259696007\n",
      "output -->  tensor([[4243.5503]], grad_fn=<AddBackward0>)  loss -->  0.00039881039992906153\n",
      "output -->  tensor([[4236.1460]], grad_fn=<AddBackward0>)  loss -->  0.0003725503629539162\n",
      "output -->  tensor([[4225.9058]], grad_fn=<AddBackward0>)  loss -->  0.0003906925267074257\n",
      "output -->  tensor([[4207.3760]], grad_fn=<AddBackward0>)  loss -->  0.0005302847130224109\n",
      "output -->  tensor([[4256.9233]], grad_fn=<AddBackward0>)  loss -->  0.00035772696719504893\n",
      "output -->  tensor([[4304.1226]], grad_fn=<AddBackward0>)  loss -->  0.0004418708849698305\n",
      "output -->  tensor([[4340.6719]], grad_fn=<AddBackward0>)  loss -->  0.0004884568625129759\n",
      "output -->  tensor([[4339.0542]], grad_fn=<AddBackward0>)  loss -->  0.0005294422735460103\n",
      "output -->  tensor([[4350.4570]], grad_fn=<AddBackward0>)  loss -->  0.00038396508898586035\n",
      "output -->  tensor([[4322.0903]], grad_fn=<AddBackward0>)  loss -->  0.00035059297806583345\n",
      "output -->  tensor([[4353.8145]], grad_fn=<AddBackward0>)  loss -->  0.0005533561925403774\n",
      "output -->  tensor([[4307.8232]], grad_fn=<AddBackward0>)  loss -->  0.0004218015819787979\n",
      "output -->  tensor([[4326.7290]], grad_fn=<AddBackward0>)  loss -->  0.0004691065405495465\n",
      "output -->  tensor([[4353.8335]], grad_fn=<AddBackward0>)  loss -->  0.0004977661883458495\n",
      "output -->  tensor([[4366.2729]], grad_fn=<AddBackward0>)  loss -->  0.0004377446311991662\n",
      "output -->  tensor([[4444.4038]], grad_fn=<AddBackward0>)  loss -->  0.0004149675078224391\n",
      "output -->  tensor([[4418.1001]], grad_fn=<AddBackward0>)  loss -->  0.00041399369365535676\n",
      "output -->  tensor([[4464.3521]], grad_fn=<AddBackward0>)  loss -->  0.0004987467546015978\n",
      "output -->  tensor([[4470.2969]], grad_fn=<AddBackward0>)  loss -->  0.00046949973329901695\n",
      "output -->  tensor([[4483.1025]], grad_fn=<AddBackward0>)  loss -->  0.00043860304867848754\n",
      "output -->  tensor([[4447.3740]], grad_fn=<AddBackward0>)  loss -->  0.00046849288628436625\n",
      "output -->  tensor([[4465.4526]], grad_fn=<AddBackward0>)  loss -->  0.0005169208743609488\n",
      "output -->  tensor([[4411.7720]], grad_fn=<AddBackward0>)  loss -->  0.0003745127469301224\n",
      "output -->  tensor([[4435.9888]], grad_fn=<AddBackward0>)  loss -->  0.0004777053545694798\n",
      "output -->  tensor([[4378.4331]], grad_fn=<AddBackward0>)  loss -->  0.0004712448862846941\n",
      "output -->  tensor([[4370.4634]], grad_fn=<AddBackward0>)  loss -->  0.0004191877960693091\n",
      "output -->  tensor([[4453.5835]], grad_fn=<AddBackward0>)  loss -->  0.0003775166696868837\n",
      "output -->  tensor([[4482.3584]], grad_fn=<AddBackward0>)  loss -->  0.00047411720152013004\n",
      "output -->  tensor([[4480.9497]], grad_fn=<AddBackward0>)  loss -->  0.0004024533263873309\n",
      "output -->  tensor([[4572.2910]], grad_fn=<AddBackward0>)  loss -->  0.00032903539249673486\n",
      "output -->  tensor([[4548.3047]], grad_fn=<AddBackward0>)  loss -->  0.0004884304944425821\n",
      "output -->  tensor([[4572.1592]], grad_fn=<AddBackward0>)  loss -->  0.0004207085003145039\n",
      "output -->  tensor([[4746.6929]], grad_fn=<AddBackward0>)  loss -->  5.0263904995517805e-05\n",
      "output -->  tensor([[5205.9072]], grad_fn=<AddBackward0>)  loss -->  0.00015629851259291172\n",
      "output -->  tensor([[5326.5488]], grad_fn=<AddBackward0>)  loss -->  0.0004513298918027431\n",
      "output -->  tensor([[5395.2095]], grad_fn=<AddBackward0>)  loss -->  0.00034974588197655976\n",
      "output -->  tensor([[5486.7817]], grad_fn=<AddBackward0>)  loss -->  0.0005090531194582582\n",
      "output -->  tensor([[5480.1152]], grad_fn=<AddBackward0>)  loss -->  0.00020202450104989111\n",
      "output -->  tensor([[5643.5078]], grad_fn=<AddBackward0>)  loss -->  0.00031883467454463243\n",
      "output -->  tensor([[5578.7261]], grad_fn=<AddBackward0>)  loss -->  0.00035829932312481105\n",
      "output -->  tensor([[5702.0171]], grad_fn=<AddBackward0>)  loss -->  0.00038254266837611794\n",
      "output -->  tensor([[5565.3633]], grad_fn=<AddBackward0>)  loss -->  0.0006595667800866067\n",
      "output -->  tensor([[5360.5396]], grad_fn=<AddBackward0>)  loss -->  0.000179736249265261\n",
      "output -->  tensor([[5357.8291]], grad_fn=<AddBackward0>)  loss -->  0.0001839195901993662\n",
      "output -->  tensor([[5357.5259]], grad_fn=<AddBackward0>)  loss -->  9.851820504991338e-05\n",
      "output -->  tensor([[5410.1016]], grad_fn=<AddBackward0>)  loss -->  0.00032065081177279353\n",
      "output -->  tensor([[5452.9854]], grad_fn=<AddBackward0>)  loss -->  0.00012484879698604345\n",
      "output -->  tensor([[5554.2827]], grad_fn=<AddBackward0>)  loss -->  0.00024576755822636187\n",
      "output -->  tensor([[5594.2764]], grad_fn=<AddBackward0>)  loss -->  0.00024273728195112199\n",
      "output -->  tensor([[5603.4888]], grad_fn=<AddBackward0>)  loss -->  0.0005710562691092491\n",
      "output -->  tensor([[5624.1890]], grad_fn=<AddBackward0>)  loss -->  0.00032961840042844415\n",
      "output -->  tensor([[5616.9390]], grad_fn=<AddBackward0>)  loss -->  0.0005153933889232576\n",
      "output -->  tensor([[5606.4971]], grad_fn=<AddBackward0>)  loss -->  0.00027585437055677176\n",
      "output -->  tensor([[5840.2949]], grad_fn=<AddBackward0>)  loss -->  0.00023618228442501277\n",
      "output -->  tensor([[5850.5449]], grad_fn=<AddBackward0>)  loss -->  0.0005327575490809977\n",
      "output -->  tensor([[5681.1074]], grad_fn=<AddBackward0>)  loss -->  0.0007300759898498654\n",
      "output -->  tensor([[5635.3154]], grad_fn=<AddBackward0>)  loss -->  0.0005252163391560316\n",
      "output -->  tensor([[5555.1479]], grad_fn=<AddBackward0>)  loss -->  0.0005789084825664759\n",
      "output -->  tensor([[5561.1421]], grad_fn=<AddBackward0>)  loss -->  0.0004975507617928088\n",
      "output -->  tensor([[5557.3188]], grad_fn=<AddBackward0>)  loss -->  0.00032626904430799186\n",
      "output -->  tensor([[5585.4053]], grad_fn=<AddBackward0>)  loss -->  0.0001260725548490882\n",
      "output -->  tensor([[5704.3438]], grad_fn=<AddBackward0>)  loss -->  0.0005799501668661833\n",
      "output -->  tensor([[5678.5049]], grad_fn=<AddBackward0>)  loss -->  5.708670141757466e-05\n",
      "output -->  tensor([[6074.2144]], grad_fn=<AddBackward0>)  loss -->  0.0002160793519578874\n",
      "output -->  tensor([[6138.5288]], grad_fn=<AddBackward0>)  loss -->  0.00019464547222014517\n",
      "output -->  tensor([[6061.0957]], grad_fn=<AddBackward0>)  loss -->  0.00013892979768570513\n",
      "output -->  tensor([[6068.4146]], grad_fn=<AddBackward0>)  loss -->  0.00020950888574589044\n",
      "output -->  tensor([[6249.1074]], grad_fn=<AddBackward0>)  loss -->  0.00035186699824407697\n",
      "output -->  tensor([[6276.1006]], grad_fn=<AddBackward0>)  loss -->  0.00019470950064714998\n",
      "output -->  tensor([[6430.8857]], grad_fn=<AddBackward0>)  loss -->  0.00019225128926336765\n",
      "output -->  tensor([[6541.7598]], grad_fn=<AddBackward0>)  loss -->  6.879465945530683e-05\n",
      "output -->  tensor([[6673.4736]], grad_fn=<AddBackward0>)  loss -->  0.0007334538968279958\n",
      "output -->  tensor([[6828.6362]], grad_fn=<AddBackward0>)  loss -->  4.495164466788992e-05\n",
      "output -->  tensor([[7140.6099]], grad_fn=<AddBackward0>)  loss -->  0.0013068317202851176\n",
      "output -->  tensor([[7584.7905]], grad_fn=<AddBackward0>)  loss -->  0.0004643613938242197\n",
      "output -->  tensor([[7756.6948]], grad_fn=<AddBackward0>)  loss -->  0.0005466249422170222\n",
      "output -->  tensor([[7674.6138]], grad_fn=<AddBackward0>)  loss -->  0.00012194350711070001\n",
      "output -->  tensor([[7090.3091]], grad_fn=<AddBackward0>)  loss -->  0.00016491695714648813\n",
      "output -->  tensor([[7297.3228]], grad_fn=<AddBackward0>)  loss -->  1.2293114195927046e-05\n",
      "output -->  tensor([[7516.1914]], grad_fn=<AddBackward0>)  loss -->  0.0012897643027827144\n",
      "output -->  tensor([[7646.2061]], grad_fn=<AddBackward0>)  loss -->  0.0003287716244813055\n",
      "output -->  tensor([[7772.7388]], grad_fn=<AddBackward0>)  loss -->  0.0001102415262721479\n",
      "output -->  tensor([[7628.1450]], grad_fn=<AddBackward0>)  loss -->  4.8928909563983325e-06\n",
      "output -->  tensor([[7595.0381]], grad_fn=<AddBackward0>)  loss -->  0.00021250807913020253\n",
      "output -->  tensor([[7773.9800]], grad_fn=<AddBackward0>)  loss -->  0.00013743039744440466\n",
      "output -->  tensor([[7881.1138]], grad_fn=<AddBackward0>)  loss -->  8.456994692096487e-05\n",
      "output -->  tensor([[7984.5986]], grad_fn=<AddBackward0>)  loss -->  0.0012828956823796034\n",
      "output -->  tensor([[8361.6455]], grad_fn=<AddBackward0>)  loss -->  0.0005745569942519069\n",
      "output -->  tensor([[8341.9189]], grad_fn=<AddBackward0>)  loss -->  0.00038408656837418675\n",
      "output -->  tensor([[8267.0283]], grad_fn=<AddBackward0>)  loss -->  0.00043840022408403456\n",
      "output -->  tensor([[8095.3770]], grad_fn=<AddBackward0>)  loss -->  9.899443830363452e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output -->  tensor([[8052.4243]], grad_fn=<AddBackward0>)  loss -->  0.0007206704467535019\n",
      "output -->  tensor([[8237.5547]], grad_fn=<AddBackward0>)  loss -->  0.0002808363933581859\n",
      "output -->  tensor([[8347.7471]], grad_fn=<AddBackward0>)  loss -->  0.0004470587591640651\n",
      "output -->  tensor([[8071.7476]], grad_fn=<AddBackward0>)  loss -->  2.8298411052674055e-05\n",
      "output -->  tensor([[7520.6006]], grad_fn=<AddBackward0>)  loss -->  6.07820984441787e-05\n",
      "output -->  tensor([[7607.2339]], grad_fn=<AddBackward0>)  loss -->  0.00010205469880020246\n",
      "output -->  tensor([[7590.0054]], grad_fn=<AddBackward0>)  loss -->  0.00014608805940952152\n",
      "output -->  tensor([[7767.6030]], grad_fn=<AddBackward0>)  loss -->  0.00019373845134396106\n",
      "output -->  tensor([[7818.5845]], grad_fn=<AddBackward0>)  loss -->  4.5845608838135377e-05\n",
      "output -->  tensor([[7661.2319]], grad_fn=<AddBackward0>)  loss -->  2.2130406307496742e-07\n",
      "output -->  tensor([[7663.5601]], grad_fn=<AddBackward0>)  loss -->  0.000308456365019083\n",
      "output -->  tensor([[7758.2163]], grad_fn=<AddBackward0>)  loss -->  6.699665391352028e-05\n",
      "output -->  tensor([[7824.5010]], grad_fn=<AddBackward0>)  loss -->  0.0002944870211649686\n",
      "output -->  tensor([[7979.6670]], grad_fn=<AddBackward0>)  loss -->  0.00017293286509811878\n",
      "output -->  tensor([[8139.3882]], grad_fn=<AddBackward0>)  loss -->  0.0008158888085745275\n",
      "output -->  tensor([[8389.2041]], grad_fn=<AddBackward0>)  loss -->  0.0005791250732727349\n",
      "output -->  tensor([[8543.7402]], grad_fn=<AddBackward0>)  loss -->  0.0005272317212074995\n",
      "output -->  tensor([[8679.5635]], grad_fn=<AddBackward0>)  loss -->  0.0011469636810943484\n",
      "output -->  tensor([[8664.5645]], grad_fn=<AddBackward0>)  loss -->  0.0004909715498797596\n",
      "output -->  tensor([[8716.0117]], grad_fn=<AddBackward0>)  loss -->  0.0009022366139106452\n",
      "output -->  tensor([[8861.]], grad_fn=<AddBackward0>)  loss -->  0.001229012617841363\n",
      "output -->  tensor([[9154.9180]], grad_fn=<AddBackward0>)  loss -->  0.0027115230914205313\n",
      "output -->  tensor([[9710.6045]], grad_fn=<AddBackward0>)  loss -->  0.0026445745024830103\n",
      "output -->  tensor([[9931.7949]], grad_fn=<AddBackward0>)  loss -->  0.002268771408125758\n",
      "output -->  tensor([[9907.6719]], grad_fn=<AddBackward0>)  loss -->  0.003374153980985284\n",
      "output -->  tensor([[10329.0986]], grad_fn=<AddBackward0>)  loss -->  0.0055052912794053555\n",
      "output -->  tensor([[11374.4727]], grad_fn=<AddBackward0>)  loss -->  0.006080096587538719\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsvXmYHGd5r30/3dXL7CPNon2zJcuWjI2xsDFLwGy2E7CyQGKTEOfExCExhySQxZzkQELiL3CSAzkkkMQBB0MA23GACGMwYBYDXuVN2JJly5Jl7ctIGs3a6/v9UfVWV1dXVVfPjDSj7ve+Ll/urq6qrtLMvL96dlFKYTAYDAZDGInZvgCDwWAwzG2MUBgMBoMhEiMUBoPBYIjECIXBYDAYIjFCYTAYDIZIjFAYDAaDIRIjFAaDwWCIxAiFwWAwGCIxQmEwGAyGSKzZvoCZoL+/X61cuXK2L8NgMBjOKB577LGjSqmBevs1hVCsXLmSzZs3z/ZlGAwGwxmFiOyOs59xPRkMBoMhEiMUBoPBYIjECIXBYDAYIjFCYTAYDIZIjFAYDAaDIRIjFAaDwWCIxAiFwWAwGCIxQmFoWp49eJLNLx6b7cswGM54jFAYmpZ/+O7z/MXXn57tyzAYzniMUBialsliiZHJ4mxfhsFwxmOEwtC0FEplxvJGKAyG6WKEwtC0FIqKsZwRCoNhuhihMDQthXKZQkmRL5Zn+1IMhjMaIxSGpqVQsgVi3LifDIZpYYTC0LQUigqAUeN+MhimhREKQ9NSsShKs3wlBsOZjREKQ9OSd4TCWBQGw/QwQmFoWool2/U0njMWhcEwHYxQGJqWgrEoDIYZIZZQiMiVIrJdRHaIyE0Bn2dE5A7n84dFZKXnsw8527eLyBWe7beKyGERedp3rr8TkWdFZIuIfE1Eeqd+e4ZWJm+yngyGGaGuUIhIEvg0cBWwDrhWRNb5drseOK6UWg18Evi4c+w64BpgPXAl8BnnfACfd7b5+S5wvlLqAuA54EMN3pPBAFQsijETzDYYpkUci+ISYIdSaqdSKg/cDmz07bMRuM15fRfwJhERZ/vtSqmcUmoXsMM5H0qp+4Ga1p5Kqe8opfQj4EPA0gbvyWAAoODEKEx1tsEwPeIIxRJgj+f9Xmdb4D7OIj8M9MU8NorfBr4V9IGI3CAim0Vk85EjRxo4paEVKJcVpbIOZhuhMBimw5wNZovInwNF4EtBnyulblFKbVBKbRgYGDi9F2eY8xTKlbYdoybryWCYFnGEYh+wzPN+qbMtcB8RsYAeYCjmsTWIyG8BbwN+XSmlYlyjwVCFdjuBCWYbDNMljlA8CqwRkVUiksYOTm/y7bMJuM55/Q7g+84Cvwm4xsmKWgWsAR6J+jIRuRL4U+BqpdR4/FsxGCoUil6LwgiFwTAd6gqFE3N4H3AvsA24Uyn1jIh8VESudnb7HNAnIjuADwA3Occ+A9wJbAW+DdyolCoBiMhXgAeBtSKyV0Sud871T0AX8F0ReVJE/mWG7tXQQuiMJzAtPAyG6WLF2UkpdQ9wj2/bhz2vJ4F3hhx7M3BzwPZrQ/ZfHeeaDIYoCuWK62m6WU+ThRKf/sEOfv8Nq2lLJ+sfYDA0GXM2mG0wTAev62m6U+4e332cf/z+Dh7aOTTdyzIYzkiMUBjmNN/ccoCh0VzDx2nXU0Km3+tpxLFITKzD0KoYoTDMWYYnCtz45cf5+pP7Gz5Wt+/obU9Pe4EfnbSPN4V7hlbFCIVhzjIyWQDsGEGj6PTY3rbUtIPZ2nVlLApDq2KEwjBn0QuzN4MpLkXnmJ72FGP5ItMpxxlxLQqTPWVoTYxQGOYs2uUzFaFwXU9tKZSCiSlYJZoxN0ZRmPI5DIYzGSMUhjlLxaJo3BpwXU/taWB61sCoKxTGojC0JkYoDHOW6biedHpsb3sKmF4g2gSzDa2OEQrDnGVsOkLhup4ci2IatRRasIxQGFoVIxSGOYsOIheKU3A9OZXZ8zq0RTF919OIEQpDi2KEwjBnmQnXU0+bIxTTsCjGjEVhaHGMUBjmLHphzk/D9eQKxTQW+REjFIYWxwiFYc4yLYvCOWaek/U0nTYeOphtsp4MrYoRCsOcRS/MxSmkx+bd9NiZcz2ZOgpDq2KEwjBnGXVaeEzF9VT09HqCqbuNymXFWL5EMiFMFsrueQ2GVsIIhWHOMhOup/Z0klRSGJtivydtiQx0Zpz3xv1kaD2MUBjmLNr1NJXKbO16shJCR8aaskWhxWpBTxYwAW1Da2KEwjBn0TGBqVoU6WQCEaEjbU25jkIHshd2Z5xrMkJhaD2MUBjmLHpxzxenVkeRSgpgu5+ma1Es7M5WvTcYWgkjFIY5y3S6xxbLipRl/3p3ZKwpZz1pYRjsNq4nQ+tihMIwJ8kVS262U7E8lRhFGSuhhSI55eFFWhgWOTEKLV4GQysRSyhE5EoR2S4iO0TkpoDPMyJyh/P5wyKy0vPZh5zt20XkCs/2W0XksIg87TvXfBH5rog87/x/3tRvz3Cm4o0pFKboeko7ric7RjG1BX5k0rieDIa6QiEiSeDTwFXAOuBaEVnn2+164LhSajXwSeDjzrHrgGuA9cCVwGec8wF83tnm5ybgPqXUGuA+572hxdBP7hkr4WYwNUKhVDauJ4NhhohjUVwC7FBK7VRK5YHbgY2+fTYCtzmv7wLeJCLibL9dKZVTSu0CdjjnQyl1P3As4Pu857oN+MUG7mdGUEpRnoK7wzBz6AV6Xnt6illPilSy4nqaataTFoYF3aaOwtC6xBGKJcAez/u9zrbAfZRSRWAY6It5rJ8FSqkDzuuDwIIY1zijfPvpg7zib77L5DTGZxqmhysUHVMVinJFKKbjesoVSVsJOjMWqaS4riiDoZWY08FspZQCAh/tReQGEdksIpuPHDkyo9+77eAIJ8YLxs0wi+gaivkdqWkIhU6PtcgVp9Z+YyxXpCtj2fUY0yjcMxjOZOIIxT5gmef9Umdb4D4iYgE9wFDMY/0cEpFFzrkWAYeDdlJK3aKU2qCU2jAwMBDjNuJzYjwPTK0i2DAz6Krs3vY0hZLCfmaIj9/1BFNzG41OFunIWPZ5pmGZGAxnMnGE4lFgjYisEpE0dnB6k2+fTcB1zut3AN93rIFNwDVOVtQqYA3wSJ3v857rOuC/Y1zjjHJsTAuFaQA3W+hg9jyn+2ujKbJ5j0WhF/rxKQS0R3MlOp3jOzOWyXoytCR1hcKJObwPuBfYBtyplHpGRD4qIlc7u30O6BORHcAHcDKVlFLPAHcCW4FvAzcqpUoAIvIV4EFgrYjsFZHrnXN9DHiLiDwPvNl5f1o57lgUU8nfN8wMY55gNjQu2lUxCmehn4o1MJorVIQia4TC0JpYcXZSSt0D3OPb9mHP60ngnSHH3gzcHLD92pD9h4A3xbmuU8WxMds/blpKzx56qpyeUFcoKkjHP75YUqTdYLbjeppC5tNorshgl50a25GxGHYeIgyGVmJOB7NnCxOjmH1GJ4t0ZiwyKXuRb3QmRaFUxvK5nqZiUYzlSu7xnZmksSgMLYkRCh9KKTdGUSwbi2K2GMsV6cgk3erqRl1PeV96LEwtmD3iCJY+z1TrMQyGMxkjFD4mCiVyTssIY1HMHqO5olO7YP+KNjoOVbcZB2h3sp6mEsweyxXpypoYhaG1MULhQ1sTYLKeZpMRRygsZ7Fv2PVUrKTHaoug0UW+WCozUSi5Fkmn0wqk0VRdg+FMxwiFj+NOIBsaf4o1zBxjuSKdWWvKrqdiuRKjaHeC2eMNuo20m6nTsSg6MhZKMeVOtAbDmYoRCh/HPVktBROjmDV0MFtbBQ3HKIqVGEV7emoWxajjqup0XFfTCYobDGcyRih8eIXCWBSzx2jOroieqlAUSoq00z02mRDaUsmGYxS66K8zY6fodjlCMWKEwtBiGKHw4Y1RmDqK2WPU6bGkhSJfbDyYrSuzwW7jMdqg60lbIB3GojC0OEYofBz3BrNNZfasoJRyLYq01XiMQillj0JNVn69OzJW4xaFIwhdbowiWbXdYGgVjFD4OD7uDWYbi2I2yBXLlMqKzqzljjNtpKZFpzV7haJ9CjUQta4n+/+mlsLQahih8HFsPE82NbXcfcPMoGc+TNX1pK0Pr+upM5Ns2GU0VuN60hZFIfQYg6EZMULh4/hY3u3t02juvmFmqCzQU3M9VYSi2qJo1PWkg9bakqjUYxiLwtBaGKHwcWwsz0CXPfbSuJ5mBx0DmGp6bD5AKMJahG/Ze4I/u2tL4OjbWovCBLMNrYkRCh8nxgvufGTTZnx2GJmcnlDoGEW6yqJIBhbK/fj5o9yxeY9bM+FlNFckm0q41eHt6SQiRigMrYcRCg9KKY6NV1xPptfTzHJ8LM8/fO+5wKd3L3oh7sx6YhQN/Cy0JWh5YhSZVMLt4eVFb8sVaj/zNgQEEBE605aZm21oOYxQeBjPl8gXy8b1dIr4wfbD/MP3nmfn0dHI/apdT/Zi38jPIihGkbGS5Aq1FkWuWKr6v5exXLVQAGZutqElMULhQRfbDXTaQmHqKGYWvYBPBjy9e5l2jKJYmx6bthKByQl5x6LIB1gbo06/KS8dmSRjU+hCazCcyRih8KDbd8zvSGMlxFgUM4x2HwU9vXsZDXA9NeIG1KKiM6bAjlcUSqrG7aUFIsgtNZorup1jNZ3ZlMl6MrQcRig86GK7eR0prKSYNuMzjF6U61oUk0USAm2ppOt6CnriDyPQ9ZQKbleeixKKycosCk1nJsnopKmjMLQWRig86PYd89rTpBIJE8yeYfQCHsei6MhYiAgiQqpB0dY/N13VDZUMKL8guBZFQPxCX4cXM+XO0IoYofCgYxTzO9KkrIQZhTrDFEIsinyxzCe+s51hx6LTDQE1qWSiRiiuu/URbv3JruDvCXA9ZSxd4R0iFAEWRVAwO6wew2BoZoxQeDg+nich0J1NOTEKY1HMJGEWxdP7h/nU93fw5UdeAvS87MoCbSWkxrp74qXjbD1wMvJ7/FlPQd+t3we5tkYCgtmdWcsEsw0tRyyhEJErRWS7iOwQkZsCPs+IyB3O5w+LyErPZx9ytm8XkSvqnVNE3iQij4vIkyLyExFZPb1bjM/x8Ty97WkSCXGeYo1QzCQ6mO23KCadQrhvPLUfqM02Slu1FsVkscxkgLsIgoUiHWZRlIItinyxTL5YpjNdmx47OmnGoRpai7pCISJJ4NPAVcA64FoRWefb7XrguFJqNfBJ4OPOseuAa4D1wJXAZ0QkWeec/wz8ulLq5cCXgb+Y3i3G5/hYgXntdl8fKynG9TTDuBaFb4GfdJ7qtx44yc4jozWFbn7XU7msyBfLoUHxfED3WFcoSmGup+pr8hb9eenMWBTLKtBVZTA0K3EsikuAHUqpnUqpPHA7sNG3z0bgNuf1XcCbRESc7bcrpXJKqV3ADud8UedUQLfzugfYP7Vba5xjY3nmd6QBjOupQQ6dnOSx3ccj93HrKHyLrHfBv3vLgZrYgN+6m4wokoNKcZ63e6yOUfgrsMNiFKOexoReOpz526boztBKxBGKJcAez/u9zrbAfZRSRWAY6Is4Nuqc7wHuEZG9wLuBj8W5kZlAu57AXpxM99j4/OuPdvLbn380cp98SLsM7UJa1JPl7i37bddTlVBI1c9CC8uUXE9h6bG+c7lDi/zB7KyZSWFoPeZiMPuPgJ9XSi0F/h34RNBOInKDiGwWkc1HjhyZkS8+Pp5nviMUVtIU3DXCaK7A8EQhspV33rUofK4nZ+H/5Vcs4blDoxw8OVn1JJ9KJtyMKXv/UtVxtd8T4HpKRmc9+QUkzKLodDrJjpiZFIYWIo5Q7AOWed4vdbYF7iMiFrbLaCji2MDtIjIAXKiUetjZfgfw6qCLUkrdopTaoJTaMDAwEOM2olFK2TGKjopFYbrHxkc/mR8+mQvdR7uPwiyKX7poKQkBpagqdPMHsytCEWJRONeSriq4C8t6CrZyRkNiFJVW48aiMLQOcYTiUWCNiKwSkTR2cHqTb59NwHXO63cA31d2Wsgm4BonK2oVsAZ4JOKcx4EeETnHOddbgG1Tv734jOVL5Etl5nfYrgW74M5YFHHRT+aHRyKEohhiUTjvl85r49Vn9wPUpMd6Rdt1PYXEKFzXk6+Fh/c6NWGV2eOOELQ7MQlNp5lJYWhBrHo7KKWKIvI+4F4gCdyqlHpGRD4KbFZKbQI+B3xRRHYAx7AXfpz97gS2AkXgRqVUCSDonM723wH+S0TK2MLx2zN6xyHoquxej+upkbYRrY5rUYxMhu5TyXoKDmZnrARvu2ARP9lxtCaY7f1ZaIEIcz1pUfFWZusWHrVpsMGBcW2ttKWChcIU3RlaibpCAaCUuge4x7ftw57Xk8A7Q469Gbg5zjmd7V8DvhbnumYStyrbFYoEYwGDbgzB5GO4nsJiFLlCiYyVQES46mWL+OoT+3j5sl7387SVqHqCr+d60tfizXoKbeERUkehrzHrEwr9Puy7DYZmJJZQtAK6c6wbozDdYxtCP5FHup5CLYqSuwD3tKW483cvq/rcnx6rjw8aNqS/J5W0+0Rpglp4KFWph/Bbj9payVrVQuGm2Rpr09BCzMWsp1nB22IcMN1jGySO6ymsuG2yUCabCv9V9DcF1E/z+VKZUkDCgS0U1eertPConKdYVugC6xqLwvmOjO+6MsaiMLQgLS8USimGRnNsP2hPXatUZidMwV0DaBE4EmlRhGQ9FUs1Lh4v/poWr+sqqOiuUFJYCanaFtTCw/s6KEYhUrEgNNmQWIfB0My0tOvpY996ltseeJEJ5+mwM2PR7RRUpZMJCqaFR2zipccGxygm8qUaF4+XlE+0J/LVxXdOWKnqe9K+BT5IKLyLfZA7TMdNqs6TTCBiLApDa9HSQrFucTfvunQ5S3rbWDqvjXWLu0k4T6KmhUdj6MrmSNdTWIyiODXXk/+1Jsj1lEwIVkKqLIcw0bDPW67JeAIQETJWwlgUhpaipYXi6gsXc/WFiwM/s0z32IbQInB8vEC+WPtED+EWxWSh5Pr+g/A3BfQeHywUqkYowJmbHeJ6qg1mh7vDsqmksSgMLUXLxyjCSJnusQ2RK5Td4rQjo8Hup0IxOEaRK5QCn941NXUUheDXmryT9eQnbVXHOnIRsQ7bygm+poyVMEJhaCmMUIRgJUwwuxFyxTJL57UBcPhksPspqtdTlOvJbuHhTY/1WBRBwexiresJ7AXeK1LafZSQWtfTRL5UE8jWZFNJ43oytBRGKELwdyw1hKOUIl8qs2xeOxBeS6FbeDSe9dRYjKJYjnA9ec6jX3dmrJqFPxdxTVnLuJ4MrYURihBM99j46EVWWxRhKbJei8I7IW6yEJ31ZCUSTs1D7YS8oKK7QojrKWMlA+MSXdlU7TClCHdYJpUIbR9iMDQjRihCSCUTlJU9Tc0QjRaAxb1tiERYFKWy2x22ahBRDNeTfbwjFHWC2fkQ11M6mfDFJbRQWDXWY9Q1Za1k6NAkg6EZMUIRgl5oTC0FPLRziKf2nAj9XD/Vt6eT9HVkOBKQIlsqK8qq0lTPv9jXcz2BJ2uqUHIX8cAYRUAdBdiCkwuwKLqzqci2In6MRWFoNYxQhKAre01AG/7mm1v5xHefC/1cP11nrCSDXZnAoju9yHc5BY16Ydb9luqlx3rPMVEo09tmV9kFLdhBldn29QWnx3a31cYoJqKEwsQoDC2GEYoQLGdxMkJhz2YYngif6KYX3EwqwWB3JtD1lC9V3DxQcRnpBTq64K56jOlkoUSv02olbsEd1FoUWuC6sinypXKVmzHS9ZRKmBb0hpbCCEUIrrvDuJ6YKJQYmQwXCr34ppMJ26IIcD3li9VCoY/RC31UMDudrI5R5Aoletq0UIQEswNcT2EWhXaHVdVYFEpuI0E/puDO0GoYoQhBD70xHWTtxXxkMnxQT85rUXRlOTqar+nqWihVL8r+uddRMQpLi7YrLmWPUARXZqcD6yiqg9BaGLrbqsUL7NhHWzqi4M5YFIYWwghFCHpxMq4ne2GOEgrX9WQlGezOUCordxCURldluzEKv0URw/WkK+UniyXa00nSViI0mB2rMrvgi5s45yqVFYWSCrVysqlkTTqtwdDMGKEIIZ00FgXYweaJQomJQin030IvsGnLdj1BbXNAf4xCL7QTrlDUD2bni7qOwg40Z32V1ppCqezGmLykfa1Aaq8pnnhlU8aiMLQWRihCcC2KFq+j8LpjRkOsCr3AZqwEA65QVAe0a7KefBZFVK+ntOVPj7X7MIXFCkJdTyl/MLvaHabf1xOvrJV0rA4jFobWwAhFCK0So/ju1kORw4a8C3GY+0k/mdsWRRaAIyfDhCI4RuGfJOfFnx5rd5tNRAhFiOvJZ1HkiiXSVsIz/a56FneYRZExw4sMLYYRihBSLRCjGM8XueGLm7lz857QfbxZRSdDMp+8dRQDYa6nsKynYgOuJyeFNVcsk7WStgsotIVHvDbjmWSiZuGvF2DPmnGohhYjllCIyJUisl1EdojITQGfZ0TkDufzh0VkpeezDznbt4vIFfXOKTY3i8hzIrJNRN4/vVucGpYvgNqMHB3JoxSM5sID1XEsCq/rKZtK0p21alxP+ZCsp1yM9NhKZbby1F04ridfMFspFTqPImMlKZaVm5Gl52ZkfNPvJmO4nrz7GQzNTt3BRSKSBD4NvAXYCzwqIpuUUls9u10PHFdKrRaRa4CPA78mIuuAa4D1wGLgeyJyjnNM2Dl/C1gGnKuUKovI4EzcaKOknMpeHUBtRo6O2Yt51II34fkszKLwup4ABruzNdXZugaiNkYRv+CuWCpXuYWCurjq7wnLegJbENrSdqvwTJXryeluW8fKMa4nQ6sRx6K4BNihlNqplMoDtwMbfftsBG5zXt8FvEnsYcMbgduVUjml1C5gh3O+qHP+HvBRpVQZQCl1eOq3N3Vaw6KoLxSNWhRAYNFdoRgWo4jveiqUylWuqqCeS/rnFTaPAiqWg9+icDOxnJnc2ZB5FBljURhajDhCsQTwOrH3OtsC91FKFYFhoC/i2Khzno1tjWwWkW+JyJp4tzKztEKMYsipdYhqcDdRJRTRFoVeQG2hCA5m+zOMGhGKfElVWSBBwWxdrxEWo7C/2z6mRijiup50Q0LTGNDQIszFYHYGmFRKbQD+Dbg1aCcRucERk81HjhyZ8YvwZ9o0I0POyNKJfPiTsbdOIdyisI/X4jrYneXwSK5q5oQWk7Z0EishFYsiRq8nt6alWHE9tTkxCr/7R39PUAuPtE8Q8qUyGStZ43qqF2D3Z0kZDM1OHKHYhx0z0Cx1tgXuIyIW0AMMRRwbdc69wFed118DLgi6KKXULUqpDUqpDQMDAzFuozFaoY7i6KhjUUQseJMxLArt67e9jdCdtcgXy1UzJ/TrdNJ+gm+k11PKU0eh9884BXe1MQpHKEK6x0JFTNz02JQ/mO2IWh2LIqjYz2BoRuIIxaPAGhFZJSJp7OD0Jt8+m4DrnNfvAL6v7MfJTcA1TlbUKmAN8Eidc34duNx5/XogvL/1KaQV6iiOxrAoJuLEKByh0Ljpo96+SsVK7MDrMposlEknEyQCFnaN92fhup6s4II7VygiYhR6gc8Xy65w2fcRr47CpMcaWo26WU9KqaKIvA+4F0gCtyqlnhGRjwKblVKbgM8BXxSRHcAx7IUfZ787ga1AEbhRKVUCCDqn85UfA74kIn8EjALvmbnbjU9LxChciyJcDPXC3JmxIoUi7bEIMp6FtNvJcqos4FJjUUQV20F199iKWygRWEdRiOF60hZFvlimo8OqdT15rJYg/DENg6HZqSsUAEqpe4B7fNs+7Hk9Cbwz5NibgZvjnNPZfgL4hTjXdSqxWiBGoS2KyRgWxWBXJrLgzmtRaJeN1zXjXcC9lkCuGD3dzj6m4nrKeQLNuo5CKeW6vSouruCZ2VCxbnKORZH2WRrGojAYqpmLwew5gfZxF5o4RuFmPcWIUfR3ZcJbeBTLVVaBXmC9biu31sJZmL11FFF9nsCXHuupms6mkihVPUciyvUUlvWUTAhWQjyupzIiBPaL0t9t72eEwtAaGKEIwVvk1YwUS2WOj9tCEZ31VEIE+jvTkcFs76IaVLnsTVv1WhQT+VJkxhNUxtLmS8rTsK8SW5gMsFzCuseCz6JwzuEdajRZKJG1kq6V4se4ngythhGKEJp9HsWxcbt9RyopkU/GE86i2ZVJRQezPVZB5Ym7egFPJoRkwhejiOF6EhHSyURV1pMOZgNVsyHyxfDKbH92kx2ETzqfJauuKWxoUdj9GQzNjBGKEFx3R5NWZutA9uLetsgFT8+O7sqGB7PzxRKZZK3radLnetKLt3fwj356r4eVFKeOotr1pK9RU/C4uPzobW4dhSe2YotXxfUUVpUNkEyILbCmjsLQIhihCEG7O5rVotBCsaS3jXypXDO6VDNRKNGWStKVTYUOL8rVxChqXU/5YqWja8YXo6iX9QS2cFfVUViJiiB5FuyoFh7eXk9gi5fe5o2bTBTqWzkZK2nqKAwtgxGKEJKuUDTnYqAznpbOawPCA7N6mpzu0RQ0vChfU0ehF/DqJ339RF9dR1F/UQZHKMp2emzGsusugmIh+YgWHt6KaqVUVf1HxjMtL1cohabGeu/RWBSGVsEIRQgitnsh36QWRUUo2oEooShXCUWQ+8kbFIZgi6JQqg4c5zxxgjhCkXZcT7lCZf8o11NU99hcsUyxrFCq4o7KWEk3e0q726LIBHSuNRiaFSMUEViJRNNaFENjeayEsKDbHjQ0EWlRJNz24EG1FHYdRVAw2ysUlRkRNRZFRDxAk7Iqrie9iAfFQuJUZudLZdf9lA6MUZTqpuz6x6oaDM1MrIK7ViWVlKbt9XR0JEdfZ7puBo92DXVHWBS1rqcAl5AnmO2vzI7teiopoBRgUQQIRVBltg5mF8ru97uup1TF9TRZLNHdloq8nqyVrMq2MhiaGWNRRKADqM3I0Fie/s6M++Qc5kbxBrMhuDFgjespqL7BE8zWFoVSKpabB+zkgrxTcKdjE8GxkPD02ERCuxO9FoV9rnSyOsBe75rCxrAaDM3+8A4FAAAgAElEQVSIsSgisJLSxFlPOfo6M3WrjP3B7MAYRaHaorCSiapW4lCdYZSxEpRVpXdTrBiF43rKq4pABA0QikqP1cfki0Gup6TreprI10/ZNTEKQythLIoIrESiaesojo7m6e9Iu4Vl4a6n6mB2UIxCz3XwYlsN1UFmr0UB9qxupaKHFmlSyQTFknKaCFa7nnIBQhFUmQ06DbZEvlRJswXb9VQpxIuX9WRiFIZWwQhFBKkmtSiUUhwdzdHflXGfnOMGs/0WRdGpwUj7YgL+9NFCUVUyjByL4ITTQiQTJ5jtuIwmi96sp6AWHuGuJ7AtjbyncC8oEyue68lYFIbWwQhFBFaTxijG8iVyxTJ9HWna0rWZQ1606yntFLj5YxT+oLDGv5DmS2U3wKzFaXjCPldUuwyNjhflCiXaUtWWib+wDyCVCHE9OZaD26SwyvVUCbDXy3rSnWu97DsxYabeGZoSIxQRWAmpmtLWLBx15ln3d2Zcl1GQRaGUcoPZAF3Z2n5P+ZhCYRfcOVlP2qJwhCJOCw9vryctEKmk3fnVX5ltJSR0EJIOWrvX7a0WdyrPi2UVozI7UdNG/YpP3s9/PPRS3XsxGM40jFBEkLYSbkuIZmJozBaKvs5KjCIo1bNQUpQ9weOgfk85X/aQxp8V5I1RaHEaHneEIm56bFFVZT0BzjjUatdTUA2FJu10iXUtoVR1C496sygq91cthMMTBUZzRfYeH697LwbDmYYRigisRHPGKPSs7H5P1lOQRVGZJlexKPzBbO1qqbEoLL9FUVnA/TGKWOmxSbEtimJ1W/IaF1ex7Hb+DSJjJarTY5NO91grSbGs3JbrdS2KVKIqLfeEI3r6/wZDM2GEIoJmjVHo9h39nZnAmgfNpG/R7A6wKPxpppqgBdzNenJjFMWq80eRTtoZaP4CvaDsqrDUWH2duUJAeqwjPsMx3WE6zdYeDQ/DE7boafEzGJoJIxQRNGtltu4cO78jjZVMkEpKsEXhaekN2vUUN5hd7RKqqqNwYxTxLYqUJ1vJm7qa8WdXeVxcQaStJLlSucYS0v93haJOgF1fs75/fdxxY1EYmhAjFBE0a6+nodEc3VnLXbjDUj21eLjB7IDhRRVff/XCmvFlBXmD2f6sJ38NRhApS9zOtVWuJ18rjWJJuTO2g9CT7IIK7rzXVK//lL9zbcX1ZCwKQ/NhhCKCVLJJs55G8/R3Zdz3YULhD+wGB7PtffzunqyVdF1XUN3Cw3XzNBjMHtOusKoGhLWWS71gtl1wVy0Uab9FESNGAbUWhc7kMhiaCSMUEViJ5o1R9HdUhKLN5+fXVISiEsz2Dy/yZw+550wnanowpTwWDHgX5fq/hlUzuWtiFD7XU0gNBVQsCp3aGup6qldHEWJRDE8UQodAGQxnKrGEQkSuFJHtIrJDRG4K+DwjInc4nz8sIis9n33I2b5dRK5o4JyfEpHRqd3WzJCyEs0ZoxjL09eZdt9nUwk328fLRI1Q1A4vCq2j8GQ9KaWqnvT1vidiLspAVSZTTdZT0ZddVcf1lAssuPMLRf30WKjEcfRxSgU3TjQYzmTqCoWIJIFPA1cB64BrRWSdb7frgeNKqdXAJ4GPO8euA64B1gNXAp8RkWS9c4rIBmDeNO9t2qQSEmlRjOeDZ0jPdY6O5ujv9FkUARXFlWB2xfUE1W086lVmK6Vc913aMzMb4j+9Q/V8ibZUuOupbjA7WV1HUWkr0tg16fvVrrdhj8vJBLQNzUYci+ISYIdSaqdSKg/cDmz07bMRuM15fRfwJhERZ/vtSqmcUmoXsMM5X+g5HRH5O+BPp3dr0yeqe+zuoTFe9pff4ak9J07zVU2PQqnMifFClUWRSSUDLYpJfzA7YHiRDiTXNgWsdIgthD29j8cLHEO1UFS5nmrqNeq4nlJJRyhKpJMJ7F/TWosiTgsPqIipN4htAtqGZiOOUCwB9nje73W2Be6jlCoCw0BfxLFR53wfsEkpdSDeLZw6rGR4Zfbe4xOUyopnD548zVc1PY47i1hfR0UobIuifowiaHiRduEEWRRgF+35p87p1ht6mFFYp1cv3hiFNx6S8cVXjozkmO+5t6Dz5IqlmmFLWsRO6kysGPMooPJvNDxRoMNJqTVFd4ZmY04Fs0VkMfBO4B9j7HuDiGwWkc1Hjhw5JdeTiuj1NJazF8uDw7nY5xseL8x60zj9FN/bXh2jmIywKLI+i2KkyqIILrjLpCrB3rxPKKAiLHH6PNnHemMU1a4nbdWUyoo9xyZY0dceep60MwtjIl+quuZGg9nagtIurBMTBVb0dTivjUVhaC7iCMU+YJnn/VJnW+A+ImIBPcBQxLFh2y8CVgM7RORFoF1EdgRdlFLqFqXUBqXUhoGBgRi30ThWMryOYsyJTxw8ORn7fL/8zz/lH773/Ixc21TRC2GPZ9RnUCdUgAlHBLQbprstKkbhcz3piu982ROjqF2Y68190HhHm1anx1au/eDJSfKlMssjhEJ/78hk0ScU/jqKeAV3rkUxXmBlv/29x8eMRWFoLuIIxaPAGhFZJSJp7OD0Jt8+m4DrnNfvAL6v7N4Gm4BrnKyoVcAa4JGwcyqlvqmUWqiUWqmUWgmMOwHyWcGKqKMYzdkLxKEGhGLv8QmeOzgyI9c2VbRbxCsUbXViFHpxDbIowlp4uAORiiUKuvW3VWsVxEmNheq24f6Cu0JJUSordg+NAbDSebIPQl/nSK5Y5XryWhQJCZ9n4b9+HbAfniiwbH47IqaWwtB81B2FqpQqisj7gHuBJHCrUuoZEfkosFkptQn4HPBF5+n/GPbCj7PfncBWoAjcqJQqAQSdc+Zvb3ro/kJBVFxP8YSiULIzbfbH3P9UEWpRhBTcZayE27I7OOuphJUQkr623t46A/1JoOsptkUR7nrS37N7yO7cunx+tOsJYHSyUG1ReHo9ZVNJN8gdRiXrqcxYvkSxrJjfnqY7mzLBbEPTEWtmtlLqHuAe37YPe15PYscWgo69Gbg5zjkD9umMc32nCiuRQCnb9+1fCMcdoYhrUWhhOTA8MbMX2SDhQhEczPYuyqmkPbzopM+iCJpQ580KSjiLblDmUmyLIqLgTl/r7qFxUklhcW9b6Hm0i2lkslgdFE9WrrcvIhju7u/5Xv1v2tueYl57ygSzDU3HnApmzzV0kVdQLYV2PQ2N5WMFqEcdoTgxXpjV+gu9qHVXCYXdettfURw0EtQ/vChXLAfGGbxP+v70WJhKMDvE9aS/p1jmpWNjLJvXXiPqXtKeGIU3rpJJBQtRGN6mgNqC6GlL0dOedjPLDIZmwQhFBNpPHVSdrS0EgMMn62c+jeUqYrL/xOy5n4YnCnRlrKrFtM3zdOzFO91O4+/3pOsR/Hif9AOD2a5FEU8oqlp4WOEWRVQg23ue0Vyx6pxh6bdR5xGx60iG3bhPmnntqariO4OhGTBCEYHlBFCDMp/GPFbB4ZH6C/+oR1hm0/10cqJQZU1A8Oxp/d6/kPuHF+WL5cCF1fuk76+jAG+MojHXU9oTM7HPUy0UKyLiE1ARgdFcddZTIiGuWMSxckSEjGX3s/K683rbUsaiMDQdRigiSLmup2CLQi92cWopqoRili2KHp9QaKvBP5NiIkAourOWW5QGtuslyKJwF/C8t46iNiAdNz3WcluU+wv77PcHTkwymiuyPCLjCSozsu1r9NV+NCheOgnghCdG0dueNjEKQ9NhhCICXTEcFKMYy5VY1W8vSnFqKbyuqv2zaFEECUXGjSdU32cuIEYx0JlxR6mCjlHU/hoFpsdOq+AuOEtKv99+yE47XlnH9eS91toiwUTVtdcj40zLG64SCjuG04xzTAytixGKCPTiFNTvaTRXZElvGxkrESvzSVsUInPXoqhxPRVrLYqBrgxHRnPuCFA76ykomF1bme1dmBvNekrXEwqnPiWqKts+T+V4v1A04nrS3z1ZLHFivEAqKbSlksxzKt5NnMLQTBihiMB1PQXUUozni3RkLBZ0Z2PVUmiLYvn89jlnUYTFKCbytcHsga4M+WKZk05AOzSY7ZnF7WY9BVgU9ZrvaXQdhV9Y9PvnDo0gAkvn1RGKgMwr932DAXbdkHB4Ik9PWxoRobfd/rc1HWQNzYQRiggqwewgi6JERybJwu5sLNeTnuGwZrCTA7NYdDc8UaCn3WdRpINjFGEWBdjN9yDc9WQlE1gJsbOeiva/XyrQopim68l5+n/hyCgLu7Ox24Pbr5OBn8XJerKvxZ5tMTxRcAWi17UoTEDb0DwYoYggqo5iLFekI22xoCcbz/WUt7Nsls1v58CJCdd1czqZLJTIFcu1FoWbOVR9nxP5cq1QdFYLRVjBHVQK+YKC2Y0GjsPcQvr6CiVV1+0E1RZFTYyiwWrxjGNRnBivWGm9zv9NvydDM2GEIoKwOopSWTFRKNGRsVjYneHg8GTdhX8sV6QzY7G4p42xfMl13ZxOTgYU24E9thRqLYpcoVQbzNYWxWjFokiH+PSzqUTV6NSgcaZxF2Ut2v6nfe/1rZgfnfEEPqFI+oXCuaaYMYqMMzTpxHjBFQgdozD9ngzNhBGKCMLqKHRldUcmyYLurOt+iGLMcVXp9hL7T5z+OIWbnePPerIaC2aDx/Xk9IMKImMlyRVq51HYnzXYPTYZHNPwXl+9Yjvv9/pfQ0VEtHDWI5tKuj9716LosP9v+j0ZmgkjFBHop9i8Tyh0lXVHxmJhTxaonyI7MlmkM5NiUa+9/2wU3QX1eYJKjCLnEYpiyW4P7l+Ye9pSpJJScT2Vwl1PbemkM7jIiVEEWRQxptt5j/ULl/e7Z8z1FNeisOxZGN64j656N0V3hmbCCEUE6ZD0WJ3q2pmxWNjtCEWdALXtekqyuEdbFKc/oB0mFHrx9bqe9MQ7v+tJRBjozHgsinLNgls5r+2ayRWjYhSNtfAIuh59rqj24v7zQHgdReysp1SS0VyR0VyR3ra0ez29baYxoKG5MEIRgS64849DdV1PaTs9Fur3expz0mkHujJYCZlTFoU3lVWj51MELZoDXRmO6hhFKbiOwj5v0m0K6J1P7T1v/KwnnR4bXrMRx/UkIp7Z3X7rpLHajmwq4f479LRVGjH3mA6yhibDCEUEViK4hYe2KNozSQa7bZ99PdfTqBPMTiaEBd3ZWSm6CxMKK5kglZRqi6IQLRRHRuyiu/pZT3Zltn8QUKNZT8mEIBImFAnmtafozqYCjqwl4+kbFXRNceMmGSuJznPwjpad154+JeNQlVKBA6YMhlONEYoIwiqzdYyiM2ORsZLM70jXF4pJWygAFvVkZ6XoLqjFuMY/vEi3Tg8VitGc61Kq53oqlMpVNRQA7c6/RXs61kgURIS3X7CYV501P/Da6/V48qJdTDWV2Q0WAXpFziu+vW2pU5Ie+7Un9rHhb77rdqs1GE4XRigisNz02LCsJ3uRW9Cd5VCMGIXef1Fv26wU3Z0Yr20xrvELxUS+el62l4HODEOjuZpRqX4yzjnzJVUVyAa47Kw+/r9fehkvX9Yb+/o/de1FvPHcBTXbL1jay+tW98c+j45T1KbHNhij8LiuvEWMve3pabXwGM8XA7Pi7t5ygLF8iZ/tG57yuQ2GqWCEIgI9pznM9aQthIXdmUiLolxWjOVLrlAs7slyIEbtxUwT1GJco5/+NZOuRVH7KzLQlaGscMUu1PXki1F4SVsJ3nXp8sghQ3H5x2sv4o+vWBt7fzdGkfILRWMxCu/x3pTj3vbptRr/xHee48p/uL/KzTRZKPHAC0cBeHq/EQrD6cUIRQRhldm6b1O7k1a6sE519rjz5N2lhaK3jXyxzNDY6U2hDOrzpGlLJasWpnrBbIC9x+2n3tBgdirhzqMIc0/NBvp6M9O1KDz7ef9d57WnGM+XYk0+DOKJPSc4OVnkvmcPudse2jnEZKGMCDxtLArDaWbu/PXOQVzXU1gdRbriejo6midfDG4trfs8dXhiFHD6i+6ihEJ3QtVot1Kg68kRin3Hx4Hw3kht2vUUEMyeTbRohabHxu0eawULRY/u9zSFWEK5rNxOuJue3O9u/+H2I2RTCV5/zgDP7D/Z8HkNhulghCKCdDLY9TSWK9KeTrqT1nQtRdikO+2q6sjYC0ulOvv0xinqCUWVqyOkjgJgoNO+X21RBHWP1eesCMXc+VWbqfRYLSydGctNpQbbooCptfHYe3yC0VyR/s40P9x+xI11/HD7YV59dj8bVsxj19ExRiZNQNtw+pg7f71zkLA6irF8sSpbZ4FjIYS5n8Z8MQ1tUdSrpdhzbJzHdh+fwpUHU9+i8MQoIlxP/V32E7PregpZWLOpBGUF4/nSnBKKTIhFoSvUteVX/zz2/v5/U93v6fgUXItbD9jWwv984xrypTL3Pn2QXUfHeHFonMvXDrB+SY+9n7EqDKeRWH+9InKliGwXkR0iclPA5xkRucP5/GERWen57EPO9u0ickW9c4rIl5ztT4vIrSISLzn+FBBeR1GiM1NZQCvV2cFFd36hmN+RJmMl6mY+feDOJ/n9Lz02tYsPIKjFuKYtlXDFAbzB7FqhaE9bdGYs9p2oF6Owt4/kCqFWx2wQ5nr6+Zct4h+vvci1+OqhLY9e37+pFo6pWBTPHjyJCLxzw1JW9LXz30/t4wfPHgbgDWsHOX+xLRRPG6EwnEbq/vWKSBL4NHAVsA64VkTW+Xa7HjiulFoNfBL4uHPsOuAaYD1wJfAZEUnWOeeXgHOBlwFtwHumdYfTIKyOYtyT6gow6Pjsw1xPI7nqGIWI2LUUETGKp/cN8+iLxzl0MjfloKiXsBbjGn+MIiqYDXacYq8TowgLVOvCtZMTRXfw0FxAi5Y/W6szY/H2CxfHPk+oRdHhdJCdQubTtgMnWdXXQXvaYuOFi3nwhSHuemwvZw90sGx+OwNdGRZ0Z3gmRkBbKcW3nz7IjsOjDV+HweAlzmPeJcAOpdROpVQeuB3Y6NtnI3Cb8/ou4E1i92vYCNyulMoppXYBO5zzhZ5TKXWPcgAeAZZO7xanjq4G9rueRn1CMa89jZUQDo/EsyigfqbUv//0Rff1oRBLpRHCWoxr/FlPOlU2rGnfQGfGneIWnh5rbx+ZLMwt15MjYNPNxAqzKHSq7FTaeGw7MMK5i7oAuPrliykr2x11+dpBd5/zF/fESpF9cOcQ7/2Px3jzJ37EL33mp3zp4d2hCRcGQxRx/lKWAHs87/c62wL3UUoVgWGgL+LYuud0XE7vBr4ddFEicoOIbBaRzUeOHIlxG1MjlUjUdo/NF+lIV560Ewlx21oEMeazKIDIyXhHR3N846n9rB7sBGam02xYi3GNv+BuslgilZSqIK0XnfkEMVxPk8W55XoKaeHRKPr+/BZFezpJOploeBzqyGSBl46Nc97CbgBWD3axbpH9+vJzK0KxfkkPOw6PusJ+6OQkH/nvpxkarf79+/LDL9GdtfhfP38uY7kif/61p/nru7c2dpMGA3M7mP0Z4H6l1I+DPlRK3aKU2qCU2jAwMHDKLsJKSoDrqVQT8BzsyoRaFNr11JX1BMC7sxw6mQssuvvKwy+RL5X5E6eIbCaquMP6PGn0NDrNRL52FoUXr1CELbg6tbZYVjUtPGaTStbT9K5JH9/Tlq7aLiIs6s2y59h4Q+d77pCdFnueIw4Av3nZClb1d7Bh5Tx32/mLuykr2HbQjlP89d1bue3B3fzj93e4+xwdzXHvMwf5lYuXcsPPnc29f/hz/OZlK/jSw7tNINzQMHH+UvYByzzvlzrbAvcREQvoAYYijo08p4h8BBgAPhDnJk4lqWSipo5CN/jzMtCV4XBE1lMyIVUL04LuLPliueaps1Aq88WHdvNz5wzwWqctxekRCttyKjld7nIBQ4u8VFsU4emxmrlkUbhZT9O8Jn1/ftcTwJrBLnfhj8vWA45QLK4IxTWXLOcHf/yGKqvtfCfz6Zl9wzyy6xh3bzlAX0eaLz/8kptgcNdjeymUFL9+6XLAFq8PvmUtPW0p/uobz8zKKF7DmUucv5RHgTUiskpE0tjB6U2+fTYB1zmv3wF834kxbAKucbKiVgFrsOMOoecUkfcAVwDXKqVm3aGaSgqFcm0dhd+iGOjKRrieSnSkk1Vttt2BRz4R+NbTBzk8kuN/vHolHRmL7qxV43r60XNHuPaWh9xFPQ71hEI//Wv3k21RhP966NnZECUUle1zqeCupy1Fd9aq+nlMhb7ONJesms8rPU/7mnMWdLLr6FhkTOCv797KDV/Y7C7a2w6cpDtrsdj53QhjUU+W+R1ptuwd5qN3P8Oinix3/O5lAHzqe89TLiu+8shLXLJyPqsHu9zjetpT/PEVa3l41zHu+dnBqdyyoUWpKxROzOF9wL3ANuBOpdQzIvJREbna2e1zQJ+I7MC2Am5yjn0GuBPYih1ruFEpVQo7p3OufwEWAA+KyJMi8uEZutcpYSWqLQq3b1O6+ml7sCvD0Fi+pt0HBFsgeo6FP6C96cn9LJ3XxuvPsd1piwMaCH5/2yEe3DkUGQz3E8f1BBWhmCyUI7uoxnE9eS2KuRTM/u3XrHIX1umQsZLc+buXcfGK2o625yzoolhWvDg0Fnr8j547wne2HuK+bXb667MHTnLuou66AiYirF/czdef3MfT+05y01Xnsnqwk3ddupy7Ht/Llx55id1D47zLsSa8XPPK5axb1M3N39xqWpYbYhPrr9fJRDpHKXW2UupmZ9uHlVKbnNeTSql3KqVWK6UuUUrt9Bx7s3PcWqXUt6LO6Wy3nG0vd/776MzdbuP4YxR6ZkNNjMKZSzE0WpsSOTpZpDNbvX/YCNUXh8Y4f3FPpeq7J1tjUewasn3fjbQAiWoxDhWLQt9f0LxsL/GC2V6LYu4IRU97qioOcCpYs8BORAhzP5XKipecn+Pffmsb+WKZZw+OuMHrepy/pIdCSXHxinlc7aT03nj5atLJBB/576eZ157iyvMX1hyXTAh/efV69g9PctuDLzZ+Y4aWZO789c5RUslElespKIMJYLArvI2Hnm5XvX8GkWrXk1KKPcfGWTa/UvC1qKetxj2166idF7+/gdjF8ER4i3GoVFfrgPZEvhTZ88grFGFuJa+ATDdwfKZx9kAnCYHnDgXXMOw/MUG+VObN5w3ywpEx/v472xnPlzhvUVfg/n5edVYf6WSCD79tnWuBDHRl+K3XrKSs4FdesTRU6C9ZNZ9XLO/l7i37Az83GPzE61XQwlgJoeDxM/v7Nmn0whk0EjXI9ZRKJujryFS5j46M2MOAls+vjPRc1GM3HMwVS2SsJPlimX1O64xGLYowawJqYxSTEcV5YFeXi1Az4tTLXHU9nQ6yqSQr+jp4PsSi2HnUdkn9zuvO4uREkVvut43wcxfGsyhef84AT33krW7bEc17X382J8bzvOd1Z0Uef8X6hfztt55l7/Fxls6rP0LW0Nq01l/vFLCSiaqCu/F8dedYTaU6u1YoxnLFmv0BFvZUz7F4yUmnXOYTCqgU3b10bNwdv9mIUJyM6PMEATGKfCm02A7shX9+ezrSUvAuYq0mFABrBjtDXU8vOkKxaqCD//UL5wGQEFi7MJ5FAdSIBNgxqL/95Qtc12YYb11vu6W+u/VQ5H4GAxihqEs6KVW9nvxDizT9ThZQUOZTUIwCnKK74VqhqLYonE6zTpxil7PAWAlpSChOjEcLhV50dIxivFCsO5dhoCtDOsI95RWaudTC43RxzoIuXhwaD2zBsuvoGJ0Zi4HODC9f1ss7L17KK5bPiz0LY7qs6u9gzWAn33nm1AiFUqrGZWo4czFCUQe/RREWo0hbCeZ3pANjFEGuJ9BFd9VCIQJL5nliFL3VnWb1k+iFy3obalMe1TkWKrMVJgtlth8cYc+xCdYvjnaDDHRlIi0KK5lwGyvOpTqK08WaBZ2UysoVdy87j46xsr/dddt9/Fcu4M4ZyMRqhCvWL+SRF48Fdrm1+0Qd4KGdQ1M696an9vPaj3/f7QdmOLNpvb/eBrESwRaFP0YBdm2B3/WklB6DWrv/wu4sx8cLrrtnz7EJFnZnq4LAlZbktijsPDrGvPYU5y3qcq2MONQTira0/aswUSjxhQdfJGMl+NUNy0L3B7hoWW/d4Kt+Qm5N15P9bxMU0H7x6Bir+jvd94mEuJlup4u3rl9Aqay4z+lOqzk8MsnvfGEz7/2Px/mz/9oypXM/sGOIYlnxyK5jM3Gphlmm9f56G8Rfme3GKAIshMHuWqHIFe1q56D99RwLHQC3M56qA4vtaYuethQHHOvhxaNjrOzvYHFvGyfGC4zni7HuI6rFOFQylI6M5PjaE/u4+sLFbhfUMD7w1rV89rpXRu6jU2Tn0ijU08VZAx0khJqAdq5YYu/xcVb1d8zSldm8bEkPi3qy3PtMpfjum1sO8NZP3s+Pnz/Kq8/uY/fQ+JSsgsdfsueobJ7BeSqG2aP1/nobxEoKxRjpsWC7Yo746iJGnDGoXQH7u3MsnGNeOjbOsoAMlEU9WdeieHFojFV9HSxpYEpevRbjUHny/9LDuxnPl7ju1SvrnjcOWoBa0aLIppKs7OuoCWjvcRISVvXPbraRiPDWdQv48fNHGBrN8Wd3beHGLz/Oir4Ovvn+1/Hht9ud/x94oTH30/BEgeed1uaPvWiEohlovb/eBrESiao2DK7rKSCLabAry5HR6kZ/UcLiLbqbLJQ4eHKyKpCtWeQU3U3kSxwYnmRVf0clyB0joF2vxThUgtk7j4zxiuW9bj+h6aItirnUwuN0smZBJ8/7XE+7jtpP6F7X02zx1vULmSyUedMnfsSdj+3hxsvP5q73XsbqwU7OGeyiryPNAzuONnTOLXtPAHa9xnOHR9xiT8OZixGKOqR8FsW40wMpqHBtsCtDoaSq5hCMRgiF28ZjeNJt5ra8r3a62qJeu+hOt4OwXU/2sXGEQmnMYzIAABLuSURBVLvD5kW4nrwZSjNlTUDFUmnFYDbozKexqhbuumByVd/sup7AXsz7O9Okkgn+4/pL+ZMrznWtv0RCuOzsPh54YaihJoKP7z6BCFz/2lUoBU+8ZKyKM53W/OttAH+MIiyDCTxFd544RdDQIk131qItleTgycnA1FjNou4sQ2N5nnXaSq/q72BBd5aExKvOvm/bYUTgkpW1PYk0VjJBKin0d2a46vxFdc8Zl7YWDmYDrFnQRVnZlppm19Ex5nekI2NGp4tUMsE3/udrue+Dr+c1TrdiL69Z3c/hkRwvHIk/Je+JPcdZM9jJa1f3k0zIjM59N8wOrfnX2wCWr44iqHOsJmgkaljdBdg+4oU99gAjPbsgMEbhxCMeesHOIFnZ30EqmWCwK3qcquabP9vPK1fMZ7A7ugjrouXz+P03nD2jgWc366kFg9lgd5EFeP5wJU6x6+jYrAeyvSzqaaM7Gyxarz67D4gfpyiXFU+8dIJXLJ9HR8bivEVdbDZxijOe1vzrbYBUoraOoj0gPgG4C7G36C7K9QSwoDvDoeFJXhoaJ2MlqnooaXSK7AM7jzLQlXFFZ3FvrVD4s6B2HB7huUOj/PzLahvE+bnzdy/jt1+7qu5+jeBmPbWoRbGqv4NkQqoC2nNNKKJYPr+dJb1t/DRmnGLX0BjDEwUuWt4LwIYV83lyz4nArsqGM4fW/OttAH/32LFcic6AmggIbuMxlrN902HuKj0Sdc/xcZbPbw/sm6SFYs+xiaoFZpGvBfmPnz/ChX/1HR7bXcld/+aWg4jAVS+bOXdSI1TmU7dmMDtjJVm/uJu7txwgVywxlity6GTujBEKEeE1q/t48IWhWPNPHnfcTK9Ybs/ouHjFPCYKJZ490NgQJ8PcwghFHVLJRNXTUFAnWE1HxqIjnaxqDDgWUaAHdi3F4ZM5dg+NB8YnoNLGA6oDoEt629h3YsINNN7zswMUSoqPbHrG/aO+52cHeOWK+W7g/HSTbeH0WM0H3nIOu4fG+cIDu92EhDNFKABefXY/JyeLsUaoPrHnBF1Zi7MHbJfbxStswdi82xTeaT7+7Wf59c8+FNjaZa7Sun+9MQmqzA4TCnBGonpiFCMR6bRgWxT5UpnnD4/WFNtp2tJJd9zmSs8Cs7jHHqc6NJZHKcUPtx+hvzPD0/tOcufmPew4PMr2QyOx3E6nikp6bOv+qr1h7SCXrx3gU/c97/rrzyyhsOMUP32hvvvpiZdO8PJlvW6V+eLeNhb3ZKdVeLfj8Agjk82RYntiPM+tP9nFT3cM8ff3bp/ty4lN6/71xqSme2yudrqdl8GubE3WU0c6GdqeQRfdlcoqVCi8+/ldTwAHTkzy3KFRDgxP8oG3nMMrV87j7+7dzu2PvDSrbido7RYeXv78F9YxUSjxd87isHIOpMbGZbA7y5rBTn60/UjkfqO5ItsPnnTdTpqLV87nsRePNzyn+/hYnj+7awtv/sT9/Oq/PtQU9Rj/9fg+csUyP3fOAP/2413c/1z0v+lcobX/emOgu8fqX/KorCeAge4MR/1CEbH/Ak876DDXE9hPZlAtFLo6e9+JCX643e7Xc/m5A3zk7es5Pp7nsz/ZxYYV82bN7QSV9NhWDWZrVg928u7LVjCaK7KoJxvYInwu84sXLeHBnUPcty282+yTL52grHAD2ZqLl/dy8OQkT+0djv19X39iH2/8vz/krsf38iuvWMqOwyO857ZHz+jxrUopvvTwbi5a3sst776YNYOdfPA/n2JotLbj9Fyjtf96Y2A5C1yprJwGf+F1FGAHtA/7sp6CWoxrFnbHEwod0F7RV9lncW+lOvuH249w7sIuFvW0cf6SHq69xJ6X/POzaE2Ax/XUosFsL3/wpjX0tqdYPTj7FdmN8juvO4u1C7r48689zUmPG0gpxQMvHOUPb3+C6297lPZ0kouWVVsUV71sEYt6srz7sw/zoCfNdiJf4r5th6qKEcFOyvjDO55kVX8H33z/a/m/v3ohn/y1l7N593Fu/PLjZ0wG1UM7h6qy3R7aeYydR8b49UtXkE0l+dS1FzE8UeBX//VBrv/8o9zwhc3c9F9buG/boTkXvzAT7upgOa0nimVFvlSmrMJTXcGOUYzmiozn7TTaqAI9vb8IKAVL59VWZWvedely1gx2Vs0rmNeeImMleP7wCJt3H6tKbf3TK9bSkU7yy69Y2sjtzjjG9VShtz3NHTdcdkaOhU1bCf7POy7glz7zU/72nm387S9fwO6hMf7kri08susYXVmLX3vlMn7jVStqCgkXdGf5r997Nb956yNcd+sj/NXG9eweGucrj7zE8ESBN5+3gH9998UkE8LJyQJ/etcWzhro4Mu/8yr39+dtFyxmeKLAn3/tad5z22b+7h0X1K0LmgmOj+XpbkuFjhAOYsfhEf7mm9v44fYjdKST/Pv/uIRLVs3nSw/vpjtr8bYL7Ie38xZ18/fvvJBbf7KLQyOTlMrw4M4hbn90D11Zi1942SI++Na1gSnzpxsjFHVIJew/6kKp7M6TrhejALsj7Mp+K3S6nXv+ZIL+zgxKBXeY1axf3MP6xdX9l0SEJb1t3P2Une10+dpB97Pe9jR//gvr6t/gKeat6xYyPFGgr04n2lahkQl2c40Ll/XyntedxS337yRjJbnj0T1YSeHmXzo/ckY32NbvXe+9jOtv28yHvvozEmLPw1jZ38E///AF/nLTM3x043o++o2tHDo5yVd//zU15/v1S1egFPz13Vt5yyfv569/8XzefsGi0FG806FQKvN/vv0s//bjXXRnLV51Vh+vPruPN567gOV9wZb/1v0n+eJDu7lz8x7a00n+5Iq1fPXxvVx36yN87Fdexr3PHOTdr1pZdV9XX7iYqy9c7L7PF8v8dMdR7t5ygK8+vo9vP3OQv3z7eja+fDFKwbaDJ9lxeJTXrRlg/mn8m4olFCJyJfD/gCTwWaXUx3yfZ4AvABcDQ8CvKaVedD77EHA9UALer5S6N+qcIrIKuB3oAx4D3q2Uqp2scppwLYqSimzwp9G1FEdGc6zs72A0V2JJb/QPdHFPdsqzCBb1Ztl5dIyujOWmIs4llve188G3rp3tyzDMEB94yzl8d+shPv/Ai7xh7QB/+8svq0rfjqK3Pc1/XH8p//3kPl67pt+d1V0uK/71/p0MjeW452cHed/lq3n5st7Ac/zGq1Zw2dl9fPDOp3j/V57gsz/eySuWz+PCZT30dWQ4Npbn6GgOpWxxWjKvjfntaQrlMoVSmWNjebbuP8nW/ScZyxf547euZc2CavE+MDzB+778BI/tPs47Ll5KUoSfvnCU72w9xF9+YytrF3Tx5nWDDHRmKCm7O/O9zxxky95h0laCay9Zxh+9+Rz6OjP86oZl/MZnH+YPbn8SsD0DUaStBJefO8jl5w7ye284iz+5awt/eMeTfPYnO9l7fMLtI5dOJrjy/IW869LlXLpq/ikRSy91hUJEksCngbcAe4FHRWSTUmqrZ7frgeNKqdUicg3wceDXRGQdcA2wHlgMfE9EznGOCTvnx4FPKqVuF5F/cc79zzNxs1NBxygK5XLdKmuwZ1JAZcbEaK5AVzb6KfLDb19HYoo/6MXOH+lrVvcb947hlJNNJbn1t17JjsOjvPm8wYYXqLZ0kmsuqV4s/+zKc9l3YoK7txzg3IVdvP9NayLPcfZAJ3e99zI+/8CLfOeZQ9zx6B4+/8CLDV3HYFeGXLHM2/7xJ/zF29bxG5cu5/BIjjsf3cOtP91FvljmU9deVPW0/+LRMb637RDf23aIf/nRzqoCxLULuvjI29fxSxctobe98mA40JXhKze8iutve5SBzkxD8anVg13c9d5X8+8/3cXXntjHW85bwKtX97F8fgffeGo/X318L5ue2s8/vesi3nbB4vonnAZxLIpLgB1KqZ0AInI7sBHwCsVG4C+d13cB/yT2b9BG4HalVA7YJSI7nPMRdE4R2Qa8EXiXs89tznlnTShSzpP+gROTbHcCU1Exh0XdbVgJ4WPf3sbBk5OcnCiGFttpLl4R3qyvHjqgffm5A1M+h8HQCKv6O2a0DiSREP7+nReyZrCLq1++OFavMSuZ4D2vO4v3vO4siqUyO46MMjJZpK8jTV+H/bC278QE+09McGKiQCoppJIJOjMW5y3qduud/vg/t/C/v/40//HgbnYcGaVUVrx2dT9/tXG9WzSoWdnf4X7nWK5IrlgmKUIyKXSkk6GiOb8jzdd+/zWUY1S2+0kmxP1OLxevmMdNV53LPT87wJvPW9DweRsljlAsAfZ43u8FLg3bRylVFJFhbNfREuAh37FLnNdB5+wDTiiligH7zwoZJ2tn46d/6m6LCi71tKe45Tcv5tM/eIG/vtvW0igLZLqsX9xNezpZFZ8wGM40sqkkf/DmaEsiDCuZ4NyFtfPde9pTrIuY+z7YleXzv/VKPv/Ai/znY3t5z+tWce0rl1cVtYbRkbHoaDDGPNOjbrOp05escsYGs0XkBuAGgOXLo/1+0+GNaxfwp1eupSubYkFXhlX9HTU+zZpjzl3AG89dwNP7hvn6E/v4xZefOq17y7oFPP6/3xIZSDQYDMEkEsJvv3bVjDfDbDbiCMU+YJnn/VJnW9A+e0XEAnqwg9pRxwZtHwJ6RcRyrIqg7wJAKXULcAvAhg0bGrfpYtLTnuL337B6Sseev6RnxibFhSEiRiQMBsMpJU7081FgjYisEpE0dnB6k2+fTcB1zut3AN9XdinzJuAaEck42UxrgEfCzukc8wPnHDjn/O+p357BYDAYpktdi8KJObwPuBc7lfVWpdQzIvJRYLNSahPwOeCLTrD6GPbCj7PfndiB7yJwo1KqBBB0Tucr/wy4XUT+BnjCObfBYDAYZglptFHXXGTDhg1q8+bNs30ZBoPBcEYhIo8ppTbU288k3hsMBoMhEiMUBoPBYIjECIXBYDAYIjFCYTAYDIZIjFAYDAaDIZKmyHoSkSPA7ike3g/UHwbcfLTifbfiPUNr3ncr3jM0ft8rlFJ1G8U1hVBMBxHZHCc9rNloxftuxXuG1rzvVrxnOHX3bVxPBoPBYIjECIXBYDAYIjFC4TQWbEFa8b5b8Z6hNe+7Fe8ZTtF9t3yMwmAwGAzRGIvCYDAYDJG0tFCIyJUisl1EdojITbN9PacCEVkmIj8Qka0i8oyI/IGzfb6IfFdEnnf+P2+2r3WmEZGkiDwhInc771eJyMPOz/sOp8V9UyEivSJyl4g8KyLbROSyZv9Zi8gfOb/bT4vIV0Qk24w/axG5VUQOi8jTnm2BP1ux+ZRz/1tE5BXT+e6WFQoRSQKfBq4C1gHXisi62b2qU0IR+KBSah3wKuBG5z5vAu5TSq0B7nPeNxt/AGzzvP848Eml1GrgOHD9rFzVqeX/Ad9WSp0LXIh9/037sxaRJcD7gQ1KqfOxxxZcQ3P+rD8PXOnbFvazvQp7/s8a7Emg/zydL25ZoQAuAXYopXYqpfLA7cDGWb6mGUcpdUAp9bjzegR74ViCfa+3ObvdBvzi7FzhqUFElgK/AHzWeS/AG4G7nF2a8Z57gJ/DmeGilMorpU7Q5D9r7Lk6bc50zXbgAE34s1ZK3Y8978dL2M92I/AFZfMQ9uTQRVP97lYWiiXAHs/7vc62pkVEVgIXAQ8DC5RSB5yPDgILZumyThX/APwpUHbe9wEnnBG70Jw/71XAEeDfHZfbZ0Wkgyb+WSul9gF/D7yELRDDwGM0/89aE/azndH1rZWFoqUQkU7gv4A/VEqd9H7mjKBtmvQ3EXkbcFgp9dj/397ds0YRRWEc/x/UFNpES4lihGCrVgEtglqJWEksDIaAH8FGG7GwtRKstBNBJOh+AC1SiUIKCzsVjJBoZaEQUjwW5y4u0Ywv7GbwzvNrdmd2Ye7wLHtmzp2dbXss22wncBy4K+kY8JVNbaYKs95LHj1PAvuBPfzcnumEUWbb5ULxETgwsDxR1lUnInaRReKBpMWyeq1/KloeP7U1vhE4AZyPiPdkS/EU2bsfL+0JqDPvFWBF0ouy/JgsHDVnfQZ4J+mzpA1gkcy/9qz7tsp2qN9vXS4UL4GpcnXEGDkB1mt5TENXevP3gDeSbg+81APmy/N54Ol2j21UJF2TNCHpEJnrM0mXgOfAhfK2qvYZQNIq8CEijpRVp8n/q682a7LlNB0Ru8tnvb/PVWc9YKtse8DlcvXTNPBloEX11zr9g7uIOEv2sncA9yXdanlIQxcRJ4El4DU/+vXXyXmKR8BB8s67s5I2T5T99yJiBrgq6VxEHCbPMPYBy8CcpPU2xzdsEXGUnMAfA94CC+QBYbVZR8RN4CJ5hd8ycIXsx1eVdUQ8BGbIO8SuATeAJ/wi21I075BtuG/AgqRX/7ztLhcKMzP7vS63nszM7A+4UJiZWSMXCjMza+RCYWZmjVwozMyskQuFmZk1cqEwM7NGLhRmZtboO6KSwwywJsrDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    raw_price_data = fetch_btc_prices()\n",
    "    data_df = parse_alphaV_JSON(raw_data=raw_price_data)\n",
    "    prices = np.array(data_df['4a. close (USD)'].tolist())\n",
    "    # -- Normalize the Data --\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    data_df = pd.DataFrame(min_max_scaler.fit_transform(data_df), columns=data_df.columns)\n",
    "    # print(data_df)\n",
    "    data_df = table_edit(data_df)\n",
    "    y_train = np.array(data_df['4a. close (USD)'].tolist())\n",
    "    data_df = data_df.drop(labels=['4a. close (USD)'],axis=1)\n",
    "    model = MLP()\n",
    "    losses, test_data_loader, loss_func, model, min_price, max_price = train(model, data_df.values,y_train,prices)\n",
    "    loss_visualize(losses)\n",
    "    validation_test(test_dataloader=test_data_loader,criterion=loss_func, model=model, norm_min=min_price, norm_max=max_price)    \n",
    "    pass\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
