{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.53\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: crypto_prediction_ws\n",
      "Azure region: canadacentral\n",
      "Resource group: crypto_prediction\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Resizing', 'allocationStateTransitionTime': '2019-08-02T03:27:17.296000+00:00', 'errors': None, 'creationTime': '2019-08-02T01:56:40.113211+00:00', 'modifiedTime': '2019-08-02T01:57:27.031652+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 6, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                                max_nodes=6)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current cluster. \n",
    "print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project directory\n",
    "\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_folder = './pytorch-price_prediction'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'pytorch1-price_prediction'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - framework_version is not specified, defaulting to version 1.1.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "estimator = PyTorch(source_directory=project_folder, \n",
    "                    script_params={'--serve': 'True','--output-dir': './outputs'},\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='train.py',\n",
    "                    use_gpu=True)\n",
    "\n",
    "# upgrade to PyTorch 1.0 Preview, which has better support for ONNX\n",
    "estimator.conda_dependencies.remove_conda_package('pytorch=1.1.0')\n",
    "#estimator.conda_dependencies.add_conda_package('pytorch-nightly')\n",
    "estimator.conda_dependencies.add_channel('pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.train.dnn._pytorch.PyTorch at 0x7fbc4c3a3278>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: pytorch1-price_prediction_1564719915_fefd9a68\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/509b3593-2de3-40ce-a6b8-a838635aecb6/resourceGroups/crypto_prediction/providers/Microsoft.MachineLearningServices/workspaces/crypto_prediction_ws/experiments/pytorch1-price_prediction/runs/pytorch1-price_prediction_1564719915_fefd9a68\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run.wait_for_completion(show_output=True)\n",
    "# run = experiment.submit(estimator)\n",
    "# print(run.get_details())\n",
    "\n",
    "# from azureml.widgets import RunDetails\n",
    "# RunDetails(run).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all the files from the run\n",
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "UserErrorException",
     "evalue": "File with path outputs/price_predictor.onnx was not found,\navailable files include: .",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mErrorResponseException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/workspace_client.py\u001b[0m in \u001b[0;36m_execute_with_arguments\u001b[0;34m(self, func, args_list, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mErrorResponseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/clientbase.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_with_base_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/clientbase.py\u001b[0m in \u001b[0;36m_execute_with_base_arguments\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m         return ClientBase._execute_func_internal(\n\u001b[0;32m--> 229\u001b[0;31m             back_off, total_retry, ssl_error_handler, self._logger, func, *args, **kwargs)\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/clientbase.py\u001b[0m in \u001b[0;36m_execute_func_internal\u001b[0;34m(cls, back_off, total_retry, ssl_error_handler, logger, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/operations/artifact_operations.py\u001b[0m in \u001b[0;36mget_content_information\u001b[0;34m(self, subscription_id, resource_group_name, workspace_name, origin, container, path, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mErrorResponseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mErrorResponseException\u001b[0m: (UserError) Cannot find Artifact with ID ExperimentRun/dcid.pytorch1-price_prediction_1564719915_fefd9a68/outputs/price_predictor.onnx in Partition ff8bf53b-9f2d-44a7-8304-1468ba6001dc.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mServiceException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/artifacts_client.py\u001b[0m in \u001b[0;36mdownload_artifact\u001b[0;34m(self, origin, container, path, output_file_path)\u001b[0m\n\u001b[1;32m    257\u001b[0m             content_info = self._execute_with_workspace_arguments(self._client.artifact.get_content_information,\n\u001b[0;32m--> 258\u001b[0;31m                                                                   origin, container, path)\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontent_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/workspace_client.py\u001b[0m in \u001b[0;36m_execute_with_workspace_arguments\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_with_workspace_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_with_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workspace_arguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/workspace_client.py\u001b[0m in \u001b[0;36m_execute_with_arguments\u001b[0;34m(self, func, args_list, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mErrorResponseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mServiceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServiceException\u001b[0m: ServiceException:\n\tCode: 404\n\tMessage: (UserError) Cannot find Artifact with ID ExperimentRun/dcid.pytorch1-price_prediction_1564719915_fefd9a68/outputs/price_predictor.onnx in Partition ff8bf53b-9f2d-44a7-8304-1468ba6001dc.\n\tDetails:\n\n\tInnerException{\n    \"additional_properties\": {},\n    \"error\": {\n        \"additional_properties\": {},\n        \"code\": \"UserError\",\n        \"message\": \"Cannot find Artifact with ID ExperimentRun/dcid.pytorch1-price_prediction_1564719915_fefd9a68/outputs/price_predictor.onnx in Partition ff8bf53b-9f2d-44a7-8304-1468ba6001dc.\",\n        \"target\": null,\n        \"details\": [],\n        \"inner_error\": null,\n        \"debug_info\": null\n    },\n    \"correlation\": {\n        \"operation\": \"2ecc4aeb3d0ae640b1908bc4771668f0\",\n        \"request\": \"vcNaa0BWB/g=\"\n    },\n    \"environment\": \"canadacentral\",\n    \"location\": \"canadacentral\",\n    \"time\": {}\n}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUserErrorException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-6d692d36d3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price_predictor.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m                                      \"therefore, the {} cannot upload files, or log file backed metrics.\".format(\n\u001b[1;32m     44\u001b[0m                                          self, self.__class__.__name__))\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, name, output_file_path)\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0moutput_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifacts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRUN_ORIGIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_check_for_data_container_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/artifacts_client.py\u001b[0m in \u001b[0;36mdownload_artifact\u001b[0;34m(self, origin, container, path, output_file_path)\u001b[0m\n\u001b[1;32m    265\u001b[0m                 raise UserErrorException(\"File with path {0} was not found,\\n\"\n\u001b[1;32m    266\u001b[0m                                          \u001b[0;34m\"available files include: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                                          \"{1}.\".format(path, \",\".join(existing_files)))\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUserErrorException\u001b[0m: File with path outputs/price_predictor.onnx was not found,\navailable files include: ."
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('outputs', 'price_predictor.onnx')\n",
    "run.download_file(model_path, output_file_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelPathNotFoundException",
     "evalue": "Could not locate the provided model_path outputs/price_predictor.onnx in the set of files uploaded to the run: []\n                See https://aka.ms/run-logging for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelPathNotFoundException\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-54b552090489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'price_predictor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mregister_model\u001b[0;34m(self, model_name, model_path, tags, properties, model_framework, model_framework_version, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \"\"\"\n\u001b[1;32m   1736\u001b[0m         return self._client.register_model(model_name, model_path, tags, properties,\n\u001b[0;32m-> 1737\u001b[0;31m                                            model_framework, model_framework_version, **kwargs)\n\u001b[0m\u001b[1;32m   1738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_run_impl/run_history_facade.py\u001b[0m in \u001b[0;36mregister_model\u001b[0;34m(self, model_name, model_path, tags, properties, model_framework, model_framework_version, asset_id)\u001b[0m\n\u001b[1;32m    356\u001b[0m             raise ModelPathNotFoundException(\n\u001b[1;32m    357\u001b[0m                 \"\"\"Could not locate the provided model_path {} in the set of files uploaded to the run: {}\n\u001b[0;32m--> 358\u001b[0;31m                 See https://aka.ms/run-logging for more details.\"\"\".format(model_path, str(run_files)))\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"prefix\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0martifact_prefix_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mmetadata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelPathNotFoundException\u001b[0m: Could not locate the provided model_path outputs/price_predictor.onnx in the set of files uploaded to the run: []\n                See https://aka.ms/run-logging for more details."
     ]
    }
   ],
   "source": [
    "model = run.register_model(model_name='price_predictor', model_path=model_path)\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from azureml.core.model import Model\n",
    "import numpy as np    # we're going to use numpy to process input and output data\n",
    "import onnxruntime    # to inference ONNX models, we use the ONNX Runtime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Inferencer(object):\n",
    "    def __init__(self):\n",
    "        self.model = self.open_model()\n",
    "    \n",
    "    def open_model(self):\n",
    "        model = TimeRNN(bat_size=1,in_features=3,h_size=1,layer_amnt=1)\n",
    "        model.load_state_dict(torch.load(config['model_save_loc']))\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def un_normalize(self,norm_val,min_val,max_val,typelist=None):\n",
    "        if(typelist):\n",
    "            for idx,item in enumerate(norm_val):\n",
    "                new_val = item * (max_val - min_val) + min_val\n",
    "                norm_val[idx] = new_val\n",
    "            return norm_val\n",
    "        else:\n",
    "            return norm_val * (max_val - min_val) + min_val \n",
    "\n",
    "    def inference(self,value, normalize_method, model,minimum_price,maximum_price):\n",
    "        value = np.array(value)\n",
    "        predictions = []\n",
    "        for sample in value:\n",
    "            sample = np.array(sample).reshape(1,-1)\n",
    "            example = torch.tensor(normalize_method.transform(sample)).float()\n",
    "            \n",
    "            if(str(device) == 'cuda'):\n",
    "                example = example.to(device)\n",
    "\n",
    "            output = model(example)\n",
    "            output_unnorm = self.un_normalize(norm_val=output.detach(),min_val=minimum_price,max_val=maximum_price)\n",
    "            predictions.append(output_unnorm)\n",
    "        return predictions\n",
    "\n",
    "    def fetch_latest_BTC_JSON(self):\n",
    "        \"\"\"Fetch the latest JSON data\"\"\"\n",
    "        API_LINK = 'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey=SAITMI5ZUMGEKGKY'\n",
    "        page = requests.get(API_LINK).json()\n",
    "        return page\n",
    "    def parse_alphaV_JSON(self,raw_data):\n",
    "        # Remove meta data for now\n",
    "        raw_data.pop('Meta Data',None)\n",
    "        # Remove key name\n",
    "        df = pd.DataFrame.from_dict(raw_data['Time Series (Digital Currency Daily)'],dtype=float)\n",
    "        # Flip dates as columns into rows\n",
    "        df = df.transpose()\n",
    "        return df\n",
    "\n",
    "\n",
    "def init():\n",
    "    global session\n",
    "    model = Model.get_model_path(model_name='price_predictor')\n",
    "    session = onnxruntime.InferenceSession(model)\n",
    "\n",
    "def preprocess(input_data_json):\n",
    "    # convert the JSON data into the tensor input\n",
    "    return np.array(json.loads(input_data_json)['data']).astype('float32')\n",
    "\n",
    "def postprocess(result):\n",
    "    \n",
    "    inf = Inferencer()\n",
    "    \n",
    "    raw_data = inf.fetch_latest_BTC_JSON()\n",
    "    df = inf.parse_alphaV_JSON(raw_data=raw_data)\n",
    "    prices = np.array(df['4a. close (USD)'].tolist())\n",
    "    data_df_temp = df.drop(labels=['1a. open (USD)','1b. open (USD)','2b. high (USD)','3b. low (USD)','4a. close (USD)','4b. close (USD)','6. market cap (USD)'],axis=1)\n",
    "    minmax_2 = preprocessing.MinMaxScaler()\n",
    "    data_df_temp = pd.DataFrame(minmax_2.fit_transform(data_df_temp), columns=data_df_temp.columns)\n",
    "\n",
    "    minimum_price = np.min(prices)\n",
    "    maximum_price = np.max(prices)   \n",
    "    res = un_normalize(norm_val=result,min_val=minimum_price,max_val=maximum_price)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def run(input_data_json):\n",
    "    try:\n",
    "        start = time.time()   # start timer\n",
    "        input_data = preprocess(input_data_json)\n",
    "        input_name = session.get_inputs()[0].name  # get the id of the first input of the model   \n",
    "        result = session.run([], {input_name: input_data})\n",
    "        end = time.time()     # stop timer\n",
    "        return {\"result\": postprocess(result),\"time\": end - start}\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return {\"error\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=[\"numpy\",\"onnxruntime\",\"azureml-core\",\"torch\",\"pyyaml\",\"pandas\",\"scikit-learn\"])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9d9112f9a80a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m image = ContainerImage.create(name = \"onnxpriceprediction\",\n\u001b[0;32m---> 14\u001b[0;31m                               \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                               \u001b[0mimage_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                               workspace = ws)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  docker_file = \"Dockerfile\",\n",
    "                                                  description = \"Price Prediction ONNX\",\n",
    "                                                  tags = {\"demo\": \"onnx\"}\n",
    "                                                 )\n",
    "\n",
    "\n",
    "image = ContainerImage.create(name = \"onnxpriceprediction\",\n",
    "                              models = [model],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
