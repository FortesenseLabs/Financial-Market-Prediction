{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: crypto-prediction-project\n",
      "Azure region: eastus2\n",
      "Resource group: crypto_prediction_resource\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'applicationInsights': '/subscriptions/509b3593-2de3-40ce-a6b8-a838635aecb6/resourcegroups/crypto_prediction_resource/providers/microsoft.insights/components/cryptopredicti1485413605',\n",
       " 'containerRegistry': '/subscriptions/509b3593-2de3-40ce-a6b8-a838635aecb6/resourceGroups/crypto_prediction_resource/providers/Microsoft.ContainerRegistry/registries/cryptopredice150b3df',\n",
       " 'creationTime': '2019-08-04T01:35:47.4531218+00:00',\n",
       " 'description': '',\n",
       " 'friendlyName': '',\n",
       " 'id': '/subscriptions/509b3593-2de3-40ce-a6b8-a838635aecb6/resourceGroups/crypto_prediction_resource/providers/Microsoft.MachineLearningServices/workspaces/crypto-prediction-project',\n",
       " 'identityPrincipalId': '82f68c0b-24dc-4c4e-a0d2-093d4bc05789',\n",
       " 'identityTenantId': '47bdc275-03cb-4246-8049-32f26432f195',\n",
       " 'identityType': 'SystemAssigned',\n",
       " 'keyVault': '/subscriptions/509b3593-2de3-40ce-a6b8-a838635aecb6/resourcegroups/crypto_prediction_resource/providers/microsoft.keyvault/vaults/cryptopredicti0282800410',\n",
       " 'location': 'eastus2',\n",
       " 'name': 'crypto-prediction-project',\n",
       " 'storageAccount': '/subscriptions/509b3593-2de3-40ce-a6b8-a838635aecb6/resourcegroups/crypto_prediction_resource/providers/microsoft.storage/storageaccounts/cryptopredicti7600175126',\n",
       " 'tags': {},\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'workspaceid': '2c038ac8-52eb-4328-80b8-a16da5e2e324'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model price_predictor.pt\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "model = Model.register(model_path = \"price_predictor.pt\",\n",
    "                       model_name = \"price_predictor.pt\",\n",
    "                       tags = {'type': \"regression\"},\n",
    "                       description = \"BTC Price prediction with PyTorch\",\n",
    "                       workspace = ws\n",
    "                      )\n",
    "\n",
    "# model = Model(name='price_predictor.pt',workspace=ws)\n",
    "# print('Registered model = ', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_deployment.ipynb\tprice_predictor.pt  scoring_file_testing.ipynb\r\n",
      "myenv.yml\t\tscore.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Model.get_model_path(model_name='price_predictor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'price_predictor.pt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from azureml.core.model import Model\n",
    "import numpy as np    # we're going to use numpy to process input and output data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class TimeRNN(nn.Module):\n",
    "    def __init__(self,bat_size,in_features,h_size,layer_amnt):\n",
    "        super(TimeRNN,self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.batch_sz = bat_size\n",
    "        self.in_features = in_features\n",
    "        self.h_size = h_size\n",
    "        self.layer_amnt = layer_amnt\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=self.in_features,\n",
    "                             hidden_size=self.h_size,\n",
    "                             num_layers=self.layer_amnt,\n",
    "                             bias=True,\n",
    "                             batch_first=False,\n",
    "                             dropout=0,\n",
    "                             bidirectional=False)\n",
    "        self.fc1 = nn.Linear(in_features=1,out_features=1)\n",
    "    def init_hidden(self):\n",
    "        \"\"\"Intialize/re-init the hidden and cell states. \n",
    "        The hidden state acts as the memory of the RNN \n",
    "        which gets passed from one unit to another. \n",
    "        h_i = f(h_i + in)\n",
    "\n",
    "        Intializing with 0s\n",
    "        \"\"\"\n",
    "        #print('layer size =\\t', self.layer_amnt)\n",
    "        #print('bat_size =\\t', self.batch_sz)\n",
    "        #print('hidden size =\\t',self.h_size)\n",
    "        return (torch.zeros(self.layer_amnt,self.batch_sz,self.h_size),\n",
    "                torch.zeros(self.layer_amnt,self.batch_sz,self.h_size))\n",
    "    def forward(self,x):\n",
    "        x = x.unsqueeze(0)\n",
    "        hidden_init = self.init_hidden()\n",
    "        h0 = hidden_init[0].to(self.device)\n",
    "        c0 = hidden_init[1].to(self.device)\n",
    "        x,hidden = self.lstm1( x,(h0,c0))\n",
    "        x = F.leaky_relu(self.fc1(x[-1].view(self.batch_sz,-1)))\n",
    "        return x\n",
    "\n",
    "class Inferencer(object):\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    def open_model(self,location):\n",
    "        model = TimeRNN(bat_size=1,in_features=3,h_size=1,layer_amnt=1)\n",
    "        model.load_state_dict(torch.load(location))\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def un_normalize(self,norm_val,min_val,max_val,typelist=None):\n",
    "        if(typelist):\n",
    "            for idx,item in enumerate(norm_val):\n",
    "                new_val = item * (max_val - min_val) + min_val\n",
    "                norm_val[idx] = new_val\n",
    "            return norm_val\n",
    "        else:\n",
    "            return norm_val * (max_val - min_val) + min_val \n",
    "\n",
    "    def inference(self,value, normalize_method, model,minimum_price,maximum_price):\n",
    "        value = np.array(value)\n",
    "        predictions = []\n",
    "        for sample in value:\n",
    "            sample = np.array(sample).reshape(1,-1)\n",
    "            example = torch.tensor(normalize_method.transform(sample)).float()\n",
    "            \n",
    "            if(str(self.device) == 'cuda'):\n",
    "                example = example.to(self.device)\n",
    "\n",
    "            output = model(example)\n",
    "            output_unnorm = self.un_normalize(norm_val=output.detach(),min_val=minimum_price,max_val=maximum_price)\n",
    "            predictions.append(np.array(output_unnorm).item())\n",
    "        return predictions\n",
    "\n",
    "    def fetch_latest_BTC_JSON(self):\n",
    "        \"\"\"Fetch the latest JSON data\"\"\"\n",
    "        API_LINK = 'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey=SAITMI5ZUMGEKGKY'\n",
    "        page = requests.get(API_LINK).json()\n",
    "        return page\n",
    "    def parse_alphaV_JSON(self,raw_data):\n",
    "        # Remove meta data for now\n",
    "        raw_data.pop('Meta Data',None)\n",
    "        # Remove key name\n",
    "        df = pd.DataFrame.from_dict(raw_data['Time Series (Digital Currency Daily)'],dtype=float)\n",
    "        # Flip dates as columns into rows\n",
    "        df = df.transpose()\n",
    "        return df\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    inf = Inferencer()\n",
    "    model_path = Model.get_model_path(model_name='price_predictor.pt')\n",
    "    #print(model_path)\n",
    "    #model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model = inf.open_model(location=model_path)\n",
    "    #model.eval()\n",
    "    \n",
    "def preprocess(input_data):\n",
    "    \"\"\"JSON Input conversion into the tensor input\"\"\"\n",
    "    input_data = json.loads(input_data)['data']\n",
    "    # -- Normalize --\n",
    "    inf = Inferencer()\n",
    "    raw_data = inf.fetch_latest_BTC_JSON()\n",
    "    df = inf.parse_alphaV_JSON(raw_data=raw_data)\n",
    "    prices = np.array(df['4a. close (USD)'].tolist())\n",
    "    data_df_temp = df.drop(labels=['1a. open (USD)','1b. open (USD)','2b. high (USD)','3b. low (USD)','4a. close (USD)','4b. close (USD)','6. market cap (USD)'],axis=1)\n",
    "    minmax_2 = preprocessing.MinMaxScaler()\n",
    "    data_df_temp = pd.DataFrame(minmax_2.fit_transform(data_df_temp), columns=data_df_temp.columns)\n",
    "\n",
    "    minimum_price = np.min(prices)\n",
    "    maximum_price = np.max(prices)\n",
    "    return input_data,minmax_2,minimum_price,maximum_price\n",
    "    \n",
    "\n",
    "def postprocess(result):\n",
    "    \n",
    "    result = np.array(result).item()\n",
    "    \n",
    "    inf = Inferencer()\n",
    "    \n",
    "    raw_data = inf.fetch_latest_BTC_JSON()\n",
    "    df = inf.parse_alphaV_JSON(raw_data=raw_data)\n",
    "    prices = np.array(df['4a. close (USD)'].tolist())\n",
    "\n",
    "    minimum_price = np.min(prices)\n",
    "    maximum_price = np.max(prices)\n",
    "\n",
    "    res = inf.un_normalize(norm_val=result,min_val=minimum_price,max_val=maximum_price)\n",
    "    return res\n",
    "\n",
    "def run(input_data_json):\n",
    "    try:\n",
    "        start = time.time()   # start timer\n",
    "        input_data,normalizer,min_price,max_price = preprocess(input_data_json) \n",
    "\n",
    "        #output = model(input_data)\n",
    "        #res = postprocess(output.detach())\n",
    "        inf = Inferencer()\n",
    "        res = inf.inference(value=input_data,\n",
    "                            normalize_method=normalizer,\n",
    "                            model=model,\n",
    "                            minimum_price=min_price,\n",
    "                            maximum_price=max_price\n",
    "                           )\n",
    "        end = time.time()     # stop timer\n",
    "        return {\"result\": res,\"time\": end - start}\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return {\"error\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r\n",
      "\n",
      "# Details about the Conda environment file format:\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
      "- python=3.5.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\r\n",
      "  - azureml-defaults\n",
      "\n",
      "  - scikit-learn\n",
      "  - numpy==1.15.1\n",
      "  - torch==1.1.0\n",
      "  - matplotlib==2.2.3\n",
      "  - pyyaml==3.11\n",
      "channels:\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.set_python_version('3.5.2')\n",
    "myenv.add_pip_package(\"scikit-learn\")\n",
    "myenv.add_pip_package(\"numpy==1.15.1\")\n",
    "myenv.add_pip_package(\"torch==1.1.0\")\n",
    "myenv.add_pip_package(\"matplotlib==2.2.3\")\n",
    "myenv.add_pip_package(\"pyyaml==3.11\")\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azureml.core.model.Model"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Image Container "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.......................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image 100epimage:1, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import Image, ContainerImage\n",
    "image_config = ContainerImage.image_configuration(runtime=\"python\",\n",
    "                                 execution_script=\"score.py\",\n",
    "                                 conda_file=\"myenv.yml\",\n",
    "                                 tags = {'type': \"regression\"},\n",
    "                                 description = \"BTC Price prediction with PyTorch\")\n",
    "image = Image.create(name = \"100epimage\",\n",
    "                     # this is the model object \n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure Container Instance WebService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                          memory_gb = 1, \n",
    "                                          tags = {\"type\": \"regression\"}, \n",
    "                                          description = 'price prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running..............................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "service_name = 'aci-price-prediction-100ep'\n",
    "service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                            image = image,\n",
    "                                            name = service_name,\n",
    "                                            workspace = ws)\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'service' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-11328dfff710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'service' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"data\": [[8700, 11080, 35000], [10800, 11090, 25000]]}'\n",
      "{'result': [9367.529296875, 11157.064453125], 'time': 0.7181339263916016}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# test_sample = json.dumps({'data': [\n",
    "#     [[8700,11080,35000]], \n",
    "# ]})\n",
    "\n",
    "\n",
    "test_sample = json.dumps({'data': [\n",
    "    [8700,11080,35000],\n",
    "    [10800,11090,25000]\n",
    "]})\n",
    "test_sample = bytes(test_sample,encoding ='utf8')\n",
    "print(test_sample)\n",
    "#print(type(test_sample))\n",
    "t = service.run(input_data=test_sample)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the webservice via HTTP request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": [8616.0498046875, 10726.2314453125], \"time\": 0.7182817459106445}\n",
      "{\"result\": [9367.529296875, 11157.064453125], \"time\": 0.8192648887634277}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "scoring_uri = 'http://f8878ff6-dd7c-475c-b4a0-0735e0524948.eastus2.azurecontainer.io/score'\n",
    "scoring_uri2 = 'http://0a719a6d-cc83-45f0-81c9-f4aa260122aa.eastus2.azurecontainer.io/score'\n",
    "\n",
    "input_data = json.dumps({'data': [\n",
    "    [8700,11080,35000],\n",
    "    [10800,11090,25000]\n",
    "]})\n",
    "\n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "# If authentication is enabled, set the authorization header\n",
    "headers['Authorization'] = 'Bearer {key}'\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.text)\n",
    "\n",
    "resp = requests.post(scoring_uri2, input_data, headers=headers)\n",
    "print(resp.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
